{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9974, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>is_incumbent</th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>percent</th>\n",
       "      <th>state</th>\n",
       "      <th>votes</th>\n",
       "      <th>won</th>\n",
       "      <th>year</th>\n",
       "      <th>count_victories</th>\n",
       "      <th>unemployement_rate</th>\n",
       "      <th>is_presidential_year</th>\n",
       "      <th>president_can_be_re_elected</th>\n",
       "      <th>president_party</th>\n",
       "      <th>president_overall_avg_job_approval</th>\n",
       "      <th>last_D_house_seats</th>\n",
       "      <th>last_R_house_seats</th>\n",
       "      <th>last_house_majority</th>\n",
       "      <th>fundraising</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>District 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>42.1</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>4281</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>200.179856</td>\n",
       "      <td>182.503597</td>\n",
       "      <td>R</td>\n",
       "      <td>552917.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>42.8</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>5202</td>\n",
       "      <td>1</td>\n",
       "      <td>1826</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>200.179856</td>\n",
       "      <td>182.503597</td>\n",
       "      <td>R</td>\n",
       "      <td>552917.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>District 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>52.2</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>7272</td>\n",
       "      <td>1</td>\n",
       "      <td>1828</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>200.179856</td>\n",
       "      <td>182.503597</td>\n",
       "      <td>R</td>\n",
       "      <td>552917.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>John Law</td>\n",
       "      <td>D</td>\n",
       "      <td>49.1</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>10868</td>\n",
       "      <td>0</td>\n",
       "      <td>1830</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>200.179856</td>\n",
       "      <td>182.503597</td>\n",
       "      <td>R</td>\n",
       "      <td>552917.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>District 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>50.9</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>11280</td>\n",
       "      <td>1</td>\n",
       "      <td>1830</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>200.179856</td>\n",
       "      <td>182.503597</td>\n",
       "      <td>R</td>\n",
       "      <td>552917.8375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     district  is_incumbent          name party  percent    state  votes  won  \\\n",
       "0  District 1           0.0  Ratliff Boon     D     42.1  Indiana   4281    1   \n",
       "1  District 1           1.0  Ratliff Boon     D     42.8  Indiana   5202    1   \n",
       "2  District 1           1.0  Ratliff Boon     D     52.2  Indiana   7272    1   \n",
       "3  District 1           0.0      John Law     D     49.1  Indiana  10868    0   \n",
       "4  District 1           1.0  Ratliff Boon     D     50.9  Indiana  11280    1   \n",
       "\n",
       "   year  count_victories  unemployement_rate  is_presidential_year  \\\n",
       "0  1824                0                 0.0                   0.0   \n",
       "1  1826                1                 0.0                   0.0   \n",
       "2  1828                2                 0.0                   0.0   \n",
       "3  1830                0                 0.0                   0.0   \n",
       "4  1830                3                 0.0                   0.0   \n",
       "\n",
       "   president_can_be_re_elected president_party  \\\n",
       "0                          1.0               0   \n",
       "1                          1.0               0   \n",
       "2                          1.0               0   \n",
       "3                          1.0               0   \n",
       "4                          1.0               0   \n",
       "\n",
       "   president_overall_avg_job_approval  last_D_house_seats  last_R_house_seats  \\\n",
       "0                            0.525667          200.179856          182.503597   \n",
       "1                            0.525667          200.179856          182.503597   \n",
       "2                            0.525667          200.179856          182.503597   \n",
       "3                            0.525667          200.179856          182.503597   \n",
       "4                            0.525667          200.179856          182.503597   \n",
       "\n",
       "  last_house_majority  fundraising  \n",
       "0                   R  552917.8375  \n",
       "1                   R  552917.8375  \n",
       "2                   R  552917.8375  \n",
       "3                   R  552917.8375  \n",
       "4                   R  552917.8375  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "house_df = pd.read_csv('data/house_mean_imputation.csv')\n",
    "#house_df = pd.read_csv('data/ready_to_use_dataset.csv')\n",
    "house_df = house_df.drop_duplicates(['year', 'state', 'district', 'name'])\n",
    "\n",
    "display(house_df.shape)\n",
    "display(house_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "last_D_house_seats    194.0\n",
       "last_R_house_seats    241.0\n",
       "Name: 9130, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(house_df.loc[(house_df['year']==2018)][['last_D_house_seats', 'last_R_house_seats']].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house_df2=house_df.set_index(['year', 'state', 'district', 'name']).dropna().copy()\n",
    "#house_df2=house_df.dropna().copy()\n",
    "#house_df2_districts=house_df2[['state','district']]\n",
    "#house_df2=house_df2.drop('state', axis=1).drop('district', axis=1).drop('name', axis=1)\n",
    "#house_df2['party']=house_df2['party'].replace(['D', 'R'], [0, 1])\n",
    "#house_df2['president_party']=house_df2['president_party'].replace(['D', 'R'], [0, 1])\n",
    "#house_df2['last_house_majority']=house_df2['last_house_majority'].replace(['D', 'R'], [0, 1])\n",
    "#data_train, data_test=house_df2[house_df2['year']!=2018], house_df2[house_df2['year']==2018]\n",
    "\n",
    "#x_train, y_train=data_train.drop('won', axis=1).drop('percent', axis=1).drop('votes', axis=1), data_train['won']\n",
    "#x_test, y_test=data_test.drop('won', axis=1).drop('percent', axis=1).drop('votes', axis=1), data_test['won']\n",
    "def splitDf(df, year):\n",
    "    dfcopy=df.dropna().copy()\n",
    "    indexed_districts=dfcopy[['state','district']]\n",
    "    dfcopy=dfcopy.drop('state', axis=1).drop('district', axis=1).drop('name', axis=1).drop('percent', axis=1).drop('votes', axis=1)\n",
    "    data_train, data_test=dfcopy[dfcopy['year']!=year], dfcopy[dfcopy['year']==year]\n",
    "\n",
    "    x_train, y_train=data_train.drop('won', axis=1), data_train['won']\n",
    "    x_test, y_test=data_test.drop('won', axis=1), data_test['won']\n",
    "    return x_train, y_train, x_test, y_test, indexed_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MutuallyExclusivePredictions(model, x_train, x_test, y_train, y_test, indexed_districts):\n",
    "    def Accuracy(y, y_pred):\n",
    "        return np.sum(y == y_pred) / len(y)\n",
    "\n",
    "    #troubleshooting 1998 data\n",
    "    #display(x_train.head())\n",
    "    #display(x_test.head())\n",
    "    #predict results\n",
    "    y_pred_train=model.predict(x_train)\n",
    "    y_pred_test=model.predict(x_test)\n",
    "\n",
    "    #calculate accuracy\n",
    "    Accu_train=Accuracy(y_train, y_pred_train)\n",
    "    Accu_val=Accuracy(y_test, y_pred_test)\n",
    "    \n",
    "    #At this stage, our predictions could lead to more than one winner per district (or none), but in reality they are mutually exclusive \n",
    "    #We will take the maximum prediction probabilities to be sure to have one and only one winner per district\n",
    "    #predict probabilities\n",
    "    y_pred_train=model.predict_proba(x_train)[:,1]\n",
    "    y_pred_test=model.predict_proba(x_test)[:,1]\n",
    "\n",
    "    #Add index to predictions from X set\n",
    "    y_pred_train_df=pd.DataFrame(y_pred_train, index=x_train.index, columns=['abs_won_proba'])\n",
    "    y_pred_test_df=pd.DataFrame(y_pred_test, index=x_test.index, columns=['abs_won_proba'])\n",
    "\n",
    "    #Join district data, party and predictions by index\n",
    "    districts_pred_train=indexed_districts.join(x_train[['party']]).join(y_pred_train_df).dropna()\n",
    "    districts_pred_test=indexed_districts.join(x_test[['party']]).join(y_pred_test_df).dropna()\n",
    "\n",
    "    #Group by district and aggregate predictions with max probability\n",
    "    districts_pred_test_grouped=districts_pred_test.groupby(['state', 'district']).agg({'abs_won_proba':('max', 'sum')})\n",
    "    districts_pred_test_grouped.columns = ['max_won_proba', 'sum_won_proba']\n",
    "    districts_pred_test_grouped = districts_pred_test_grouped.reset_index(drop=False)\n",
    "\n",
    "    #Create won_pred response variable (at this stage we have only the winner candidates)\n",
    "    districts_pred_test_grouped['won_pred']=1\n",
    "\n",
    "    #join district and party data with max predictions probabilities \n",
    "    out_df=districts_pred_test.join(districts_pred_test_grouped.set_index(['state', 'district', 'max_won_proba'])['won_pred'],on=['state', 'district', 'abs_won_proba']).fillna(0)\n",
    "\n",
    "    #join district and party data with sum predictions probabilities \n",
    "    out_df=out_df.join(districts_pred_test_grouped.set_index(['state', 'district'])['sum_won_proba'],on=['state', 'district'])\n",
    "    \n",
    "    #calculate relative probability. That takes into account the predictions of the other candidates within the same district\n",
    "    out_df['rel_won_proba']=out_df['abs_won_proba']/out_df['sum_won_proba']\n",
    "    #display(out_df[(out_df['state']=='Louisiana')&(out_df['district']=='District 3')]) #&(out_df['year']==2018)])\n",
    "    \n",
    "    #check to have only and one only winner per district \n",
    "    districtWinners=out_df.groupby(['state', 'district'])['won_pred'].sum().reset_index(drop=False)\n",
    "    NotJustOneWinner=districtWinners[districtWinners['won_pred']!=1]\n",
    "    if (len(NotJustOneWinner)>0): \n",
    "        warnings.warn(\"{} districts have no winner or more than one winner\".format(len(NotJustOneWinner), DeprecationWarning))\n",
    "        display(districtWinners[districtWinners['won_pred']!=1])\n",
    "        display(out_df[(out_df['state']==NotJustOneWinner.iloc[0]['state'])&(out_df['district']==NotJustOneWinner.iloc[0]['district'])])\n",
    "        districts_x_test=indexed_districts.join(x_test).join(y_pred_test_df).dropna()\n",
    "        display(districts_x_test[(districts_x_test['state']==NotJustOneWinner.iloc[0]['state'])&(districts_x_test['district']==NotJustOneWinner.iloc[0]['district'])])\n",
    "        #mange conflicts: if more than one candidate have the same prediction probability, set all to zero\n",
    "        #if they are all from the same party, though, set the first to one (we aim to predict party wins, not specific candidates)\n",
    "        for state in NotJustOneWinner['state']:\n",
    "            for district in NotJustOneWinner[NotJustOneWinner['state']==state]['district']:\n",
    "                i=np.zeros(len(out_df.loc[(out_df['state']==state)&(out_df['district']==district)&(out_df['won_pred']==1), 'won_pred'])) \n",
    "                if (len(out_df.loc[(out_df['state']==state)&(out_df['district']==district)&(out_df['won_pred']==1), 'party'].unique())==1):\n",
    "                    print('The conflict is from candidates from the same party, so we predict as winner in the district the first candidate of this party')\n",
    "                    i[0]=1\n",
    "                out_df.loc[(out_df['state']==state)&(out_df['district']==district)&(out_df['won_pred']==1), 'won_pred']=i\n",
    "                #display(out_df.loc[(out_df['state']==state)&(out_df['district']==district), 'won_pred'])\n",
    "    #assert len(NotJustOneWinner) == 0, \"{} districts have no winner or more than one winner\".format(len(NotJustOneWinner))\n",
    "    \n",
    "    #validation accuracy score\n",
    "    Accu_val_2=Accuracy(y_test, out_df['won_pred'])\n",
    "    #Accu_val_2=sum(out_df['won_pred']==y_test)/len(out_df)\n",
    "    \n",
    "    #display(out_df.head())\n",
    "    \n",
    "    return Accu_train, Accu_val, Accu_val_2, out_df.drop('sum_won_proba', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deductPartisanship(trainData):\n",
    "    #compute the prevalence of one party win against the other\n",
    "    house_df_all_districts=trainData[(trainData['won']==1)].groupby(['state', 'district'])['party'].sum().reset_index(drop=False)\n",
    "    house_df_all_districts['R_occurence']=house_df_all_districts['party'].str.count('R')/house_df_all_districts['party'].str.len()\n",
    "\n",
    "    avgHistData=house_df_all_districts['party'].str.len().mean() #Average amount of historical data per district\n",
    "    histDataThreshold=avgHistData/2\n",
    "\n",
    "    #3=traditionally Republican district\n",
    "    #2=traditionally Democratic district\n",
    "    #1=swing district\n",
    "    #0=Recent district (Not enough historical data)\n",
    "    house_df_all_districts['partisanship']=(house_df_all_districts['party'].str.len()>=histDataThreshold)*(\n",
    "                      (house_df_all_districts['R_occurence']>(2/3))*3\n",
    "                    + (house_df_all_districts['R_occurence']<=(1/3))*2\n",
    "                    + ((house_df_all_districts['R_occurence']>(1/3))\n",
    "                      &(house_df_all_districts['R_occurence']<=(2/3)))*1\n",
    "                    )\n",
    "    return house_df_all_districts[['state', 'district', 'partisanship']]\n",
    "\n",
    "def assignPartisanship(x_train, y_train, indexed_districts, x_test):\n",
    "    train_df=x_train.copy()\n",
    "    train_df['won']=y_train\n",
    "    train_df=indexed_districts.join(train_df).dropna()\n",
    "    test_df=indexed_districts.join(x_test.copy()).dropna()\n",
    "\n",
    "    out_df=test_df.join(deductPartisanship(train_df).set_index(['state', 'district']), on=['state', 'district']).drop('state', axis=1).drop('district', axis=1)\n",
    "    #display(out_df[out_df['partisanship'].isna()])\n",
    "    return out_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_train, y_train, indexed_districts, df):\n",
    "    df_out=df.copy()\n",
    "    \n",
    "    #first_time_elected relative to election year and non-negative\n",
    "    df_out.loc[df_out['first_time_elected']>0, 'first_time_elected']=df_out['year']-df_out['first_time_elected']\n",
    "    df_out.loc[df_out['first_time_elected']<0, 'first_time_elected']=0\n",
    "    \n",
    "    #Assign district partisanship\n",
    "    df_out=assignPartisanship(x_train, y_train, indexed_districts, df_out)\n",
    "    df_out=pd.get_dummies(df_out, columns=['partisanship'], drop_first=True)\n",
    "\n",
    "    #replace 'D' and 'R' with 0 and 1 \n",
    "    df_out['party']=df_out['party'].replace(['D', 'R'], [0, 1])\n",
    "    df_out['president_party']=df_out['president_party'].replace(['D', 'R'], [0, 1])\n",
    "    df_out['last_house_majority']=df_out['last_house_majority'].replace(['D', 'R'], [0, 1])\n",
    "    \n",
    "    #calculate Log10 of fundraising\n",
    "    df_out['Log10fundraising']=df_out['fundraising']\n",
    "    df_out.loc[df_out['Log10fundraising']<=0, 'Log10fundraising']=np.NaN\n",
    "    df_out['Log10fundraising']=np.log10(df_out['Log10fundraising']) #take the log10\n",
    "    df_out.loc[df_out['Log10fundraising'].isna(), 'Log10fundraising']=0\n",
    "\n",
    "    #Standardize\n",
    "    scaler = StandardScaler().fit(x_train)\n",
    "    df_out=scaler.transform(df)\n",
    "    \n",
    "    #Ratio of R vs D seats before election\n",
    "    df_out['last_R_vs_D_Seats']=df_out['last_R_house_seats']/(df_out['last_R_house_seats']+df_out['last_D_house_seats']) #1=100% R, 0=100% D\n",
    "    df_out=df_out.drop('last_R_house_seats', axis=1).drop('last_D_house_seats', axis=1)\n",
    "    \n",
    "    #drop linear fundraising\n",
    "    df_out=df_out.drop('fundraising', axis=1)\n",
    "    \n",
    "    #drop year\n",
    "    #df_out=df_out.drop('year', axis=1)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDf(df, year):\n",
    "    dfcopy=df.dropna().copy()\n",
    "    indexed_districts=dfcopy[['state','district']]\n",
    "    dfcopy=dfcopy.drop('state', axis=1).drop('district', axis=1).drop('name', axis=1).drop('percent', axis=1).drop('votes', axis=1)\n",
    "    data_train, data_test=dfcopy[dfcopy['year']!=year], dfcopy[dfcopy['year']==year]\n",
    "\n",
    "    x_train, y_train=data_train.drop('won', axis=1), data_train['won']\n",
    "    x_test, y_test=data_test.drop('won', axis=1), data_test['won']\n",
    "    return x_train, y_train, x_test, y_test, indexed_districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "def plotYearscores(years, scores_train, scores_train_CV, title, xlabel='Year'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    fig.suptitle(title, fontsize=24, y=1.0)\n",
    "    ax.plot(depths, scores_train, label = 'Full training set')\n",
    "    ax.plot(depths, scores_train_CV, label = 'Cross validation means')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xticks(years)\n",
    "    ax.legend();\n",
    "    \n",
    "def modelListTrain(modelList, train_data, years):\n",
    "    for i in range(len(modelList)):\n",
    "    #for i in [1]:\n",
    "        model=modelList[i]\n",
    "        #model=dict()\n",
    "        #model['model']=modelType\n",
    "        #list with training accuracy\n",
    "        train_acc=[]\n",
    "        #list with validation accuracy\n",
    "        val_acc=[]\n",
    "        #list with mutually exclusive validation accuracy\n",
    "        val_acc_2=[]\n",
    "        #list with uncertainties\n",
    "        n_uncertain=[]\n",
    "        for year in years:\n",
    "            print('model: {}'.format(model['name']))\n",
    "            print('year: {}'.format(year))\n",
    "            #split dataset\n",
    "            x_train, y_train, x_val, y_val, house_df_districts = splitDf(train_data, year)\n",
    "\n",
    "            #preprocess\n",
    "            x_train_preprocess=preprocess(x_train, y_train, house_df_districts, x_train)\n",
    "            x_val_preprocess=preprocess(x_train, y_train, house_df_districts, x_val)\n",
    "\n",
    "            #remove columns which are not in both datasets, like set(dataset1)^set(dataset2)\n",
    "            x_train_preprocess=x_train_preprocess[list(x_val_preprocess)]\n",
    "\n",
    "            #fit model\n",
    "            #display(x_train_preprocess.head())\n",
    "            fitted_model=model['model'].fit(x_train_preprocess, y_train)\n",
    "\n",
    "            #generate predictions and calculate accuracy\n",
    "            Accu_train, Accu_val, Accu_val_2, pred_df = MutuallyExclusivePredictions(fitted_model, x_train_preprocess, x_val_preprocess, y_train, y_val, house_df_districts)\n",
    "\n",
    "            #store accuracy\n",
    "            train_acc.append(Accu_train)\n",
    "            val_acc.append(Accu_val)\n",
    "            val_acc_2.append(Accu_val_2)\n",
    "\n",
    "            #print accuracy scores\n",
    "            print('Training accuracy: {:.2%}\\nValidation accuracy: {:.2%}\\nMutually exclusive validation accuracy: {:.2%}'.format(Accu_train, Accu_val, Accu_val_2))\n",
    "\n",
    "            #print how many republican, how many democrat districts\n",
    "            DEM=pred_df[(pred_df['won_pred']==1)&(pred_df['party']==0)]\n",
    "            REP=pred_df[(pred_df['won_pred']==1)&(pred_df['party']==1)]\n",
    "            print('N. Democrat districts: {}\\nN. Republican districts: {}'.format(len(DEM), len(REP)))\n",
    "\n",
    "            #print uncertainties\n",
    "            uncertainties=pred_df[(pred_df['rel_won_proba']<0.8) & (pred_df['abs_won_proba']>0.5)]\n",
    "            n_uncertainties=len(pred_df[(pred_df['rel_won_proba']<0.8) & (pred_df['abs_won_proba']>0.5)])\n",
    "            n_uncertain.append(n_uncertainties)\n",
    "            print('Uncertainties: {}\\n'.format(n_uncertainties))\n",
    "        \n",
    "        modelList[i]['score train']=np.mean(train_acc)\n",
    "        modelList[i]['score validation']=np.mean(val_acc)\n",
    "        modelList[i]['score val mut exclusive']=np.mean(val_acc_2)\n",
    "        modelList[i]['N. uncertainties']=np.mean(n_uncertain)\n",
    "    display(modelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'first_time_elected'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3062\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3063\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'first_time_elected'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-da102eabd32f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#preprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mx_train_preprocess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhouse_df_districts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mx_test_preprocess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhouse_df_districts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-0ec020dc4ad3>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(x_train, y_train, indexed_districts, df)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#first_time_elected relative to election year and non-negative\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdf_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'first_time_elected'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'first_time_elected'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'first_time_elected'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mdf_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'first_time_elected'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'first_time_elected'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2683\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2684\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2685\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2690\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2484\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2486\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2487\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3065\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'first_time_elected'"
     ]
    }
   ],
   "source": [
    "#one shot prediction\n",
    "model=LogisticRegressionCV(cv=5, penalty='l2', max_iter=2500)\n",
    "\n",
    "#split dataset\n",
    "year=2018\n",
    "x_train, y_train, x_test, y_test, house_df_districts = splitDf(house_df, year)\n",
    "\n",
    "#preprocess\n",
    "x_train_preprocess=preprocess(x_train, y_train, house_df_districts, x_train)\n",
    "x_test_preprocess=preprocess(x_train, y_train, house_df_districts, x_test)\n",
    "\n",
    "#fit model\n",
    "#display(x_train_preprocess.head())\n",
    "fitted_model=model.fit(x_train_preprocess, y_train)\n",
    "\n",
    "#generate predictions and calculate accuracy\n",
    "Accu_train, Accu_val, Accu_val_2, pred_df = modelPredictions(fitted_model, x_train_preprocess, x_test_preprocess, y_train, y_test, house_df_districts)\n",
    "\n",
    "#print accuracy scores\n",
    "print('Training accuracy: {:.2%}\\nValidation accuracy: {:.2%}\\nMutually exclusive validation accuracy: {:.2%}\\n'.format(Accu_train, Accu_val, Accu_val_2))\n",
    "\n",
    "#print how many republican, how many democrat districts\n",
    "DEM=pred_df[(pred_df['won_pred']==1)&(pred_df['party']==0)]\n",
    "REP=pred_df[(pred_df['won_pred']==1)&(pred_df['party']==1)]\n",
    "print('N. Democrat districts: {}\\nN. Republican districts: {}'.format(len(DEM), len(REP)))\n",
    "\n",
    "#print uncertainties\n",
    "#display(pred_df[(pred_df['rel_won_proba']<0.8) & (pred_df['abs_won_proba']>0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set on 2018 data, train set on previous data\n",
    "#train_data, test_data = house_df[house_df['year']!=2018], house_df[house_df['year']==2018]\n",
    "train_data, test_data = house_df[(house_df['year']>=1918)&(house_df['year']!=2018)], house_df[house_df['year']==2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Years lists\n",
    "Midterm_recent_years=2014-4*np.arange(10)\n",
    "All_recent_years=2016-2*np.arange(20)\n",
    "display(Midterm_recent_years)\n",
    "display(All_recent_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelList=[]\n",
    "model=dict()\n",
    "model['name']='Logistic Regression CV=5'\n",
    "model['model']=LogisticRegressionCV(cv=5, penalty='l2', max_iter=2500)\n",
    "modelList.append(model)\n",
    "#model=dict()\n",
    "#model['name']='k-NN, k=4'\n",
    "#model['model']=KNeighborsClassifier(n_neighbors=4)\n",
    "#modelList.append(model)\n",
    "model=dict()\n",
    "model['name']='LDA'\n",
    "model['model']=LinearDiscriminantAnalysis(store_covariance=True)\n",
    "modelList.append(model)\n",
    "model=dict()\n",
    "model['name']='QDA'\n",
    "model['model']=QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "modelList.append(model)\n",
    "\n",
    "years=Midterm_recent_years\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelListTrain(modelList, train_data, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "def plotCVscores(depths, scores_train, scores_train_CV, scores_train_CVstd, title, xlabel='Depth'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    fig.suptitle(title, fontsize=24, y=1.0)\n",
    "    ax.plot(depths, scores_train, label = 'Full training set')\n",
    "    ax.plot(depths, scores_train_CV, label = 'Cross validation means')\n",
    "    upper=np.array(scores_train_CV)+2*np.array(scores_train_CVstd)\n",
    "    lower=np.array(scores_train_CV)-2*np.array(scores_train_CVstd)\n",
    "    ax.fill_between(depths, lower, upper, color='chocolate', alpha='0.1')\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel('Score')\n",
    "    #ax.set(ylim=([0.95*min(lower),1.05*max(upper)])) #I guess this is the meaning of \"set the y-axis to focus on the cross-validation performance.\"\n",
    "    ax.set_xticks(depths)\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#find best depth for decision tree\n",
    "#years=Midterm_recent_years\n",
    "years=All_recent_years[:5]\n",
    "for year in years:\n",
    "    #split dataset\n",
    "    x_train, y_train, x_val, y_val, house_df_districts = splitDf(train_data, year)\n",
    "\n",
    "    #preprocess\n",
    "    x_train_preprocess=preprocess(x_train, y_train, house_df_districts, x_train)\n",
    "    x_val_preprocess=preprocess(x_train, y_train, house_df_districts, x_val)\n",
    "\n",
    "    #remove columns which are not in both datasets, like set(dataset1)^set(dataset2)\n",
    "    x_train_preprocess=x_train_preprocess[list(x_val_preprocess)]\n",
    "\n",
    "    #fit model\n",
    "    depths=list(range(1,21)) #set (maximum) tree depths 1, 2, 3, ..., 20\n",
    "    scores_train = []\n",
    "    scores_train_CV = []\n",
    "    scores_train_CVstd = []\n",
    "    for depth in depths:\n",
    "        dt = DecisionTreeClassifier(max_depth = depth)\n",
    "        scores = cross_val_score(estimator=dt, X=x_train_preprocess, y=y_train, cv=5)\n",
    "        scores_train_CV.append(scores.mean()) #cross-validated score\n",
    "        scores_train_CVstd.append(scores.std()) #cross-validated score\n",
    "        dt.fit(x_train_preprocess, y_train)\n",
    "        scores_train.append(dt.score(x_train_preprocess, y_train)) #score on training data\n",
    "\n",
    "    #plot\n",
    "    title='{}. Single decision tree score on full training vs CV=5 set'.format(year)\n",
    "    plotCVscores(depths, scores_train, scores_train_CV, scores_train_CVstd, title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add decision tree model\n",
    "max_depth=4\n",
    "model=dict()\n",
    "model['name']='Decision Tree, depth={}'.format(max_depth)\n",
    "model['model']=DecisionTreeClassifier(max_depth = max_depth)\n",
    "modelList.append(model)\n",
    "max_depth=5\n",
    "model=dict()\n",
    "model['name']='Decision Tree, depth={}'.format(max_depth)\n",
    "model['model']=DecisionTreeClassifier(max_depth = max_depth)\n",
    "modelList.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelListTrain(modelList[-2:], train_data, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScores(models_names, scores_train, scores_val, scores_val_mut_escl, baseline_accuracy):\n",
    "    #plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    fig.suptitle('Scores of all fitted models on training vs validation set', fontsize=24, y=1)\n",
    "    ax.barh(models_names, scores_train, alpha=0.5, label='train set') \n",
    "    ax.barh(models_names, scores_val, alpha=0.5, label='val set')   \n",
    "    ax.barh(models_names, scores_val_mut_escl, alpha=0.5, label='val set mut. excl.')  \n",
    "    max_scores=np.maximum(np.maximum(np.array(scores_train),np.array(scores_val)),np.array(scores_val_mut_escl))\n",
    "    for i, v in enumerate(max_scores):\n",
    "        ax.text(v+0.005, i, '{:<.2%}'.format(v), color='black', fontsize=12)\n",
    "        #ax.text(scores_val[i]+0.015, i, '{:.4}'.format(v), color='royalblue', fontsize=12)\n",
    "    min_scores=np.minimum(np.minimum(np.array(scores_train),np.array(scores_val)),np.array(scores_val_mut_escl))\n",
    "    for i, v in enumerate(min_scores):\n",
    "        ax.text(v-0.03, i, '{:>.2%}'.format(v), color='white', fontsize=12)    \n",
    "    ax.axvline(x=baseline_accuracy, c='g', label='baseline')\n",
    "    #ax.text(baseline_accuracy, 0, '{:.2%}'.format(baseline_accuracy), color='green', horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
    "    ax.set_xlabel('Score')\n",
    "    plt.xlim(baseline_accuracy*0.95,1)\n",
    "    fig.legend(bbox_to_anchor=(1.25, 0.88));\n",
    "def plotModelsScores(modelList, baseline_accuracy):\n",
    "    models_names=[]\n",
    "    scores_train=[] \n",
    "    scores_val=[] \n",
    "    scores_val_mut_escl=[]\n",
    "    for model in modelList:\n",
    "        models_names.append(model['name'])\n",
    "        scores_train.append(model['score train'])\n",
    "        scores_val.append(model['score validation'])\n",
    "        scores_val_mut_escl.append(model['score val mut exclusive'])\n",
    "    plotScores(models_names, scores_train, scores_val, scores_val_mut_escl, baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "baseline_accuracy=0.7 #TO BE UPDATED\n",
    "plotModelsScores(modelList, baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house_df[(house_df['state']=='Louisiana')&(house_df['district']=='District 3')&(house_df['year']==2018)]\n",
    "#house_df[(house_df['state']=='California')&(house_df['district']=='District 17')&(house_df['year']==2014)]\n",
    "house_df[(house_df['state']=='Colorado')&(house_df['district']=='District 3')&(house_df['year']==2014)]\n",
    "#house_df.iloc[[9600, 9801, 9813, 9904], :] #9600, 9801, 9813, 9904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(house_df[(house_df['year']==1998)]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_df['abs_won_proba'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_df['rel_won_proba'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
