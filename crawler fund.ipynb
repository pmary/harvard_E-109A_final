{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define some usefull functions we will use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_or_save_page(filename, url):\n",
    "    \"\"\"\n",
    "        Check if the file exist, if not get the page\n",
    "        from the url and store in on the disk\n",
    "        Returns the file content as a soup\n",
    "    \"\"\"\n",
    "    # Check if the page has been stored on disk\n",
    "    if Path(filename).is_file() is False:\n",
    "        #print('No page')\n",
    "        # Get the page\n",
    "        result = requests.get(url)\n",
    "        with open(filename,'w') as outfile:\n",
    "            outfile.write(result.text)\n",
    "        time.sleep(2)\n",
    "    #else:\n",
    "        #print('We got it')\n",
    "        \n",
    "    with open(filename) as my_file:\n",
    "        soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "        \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection - Web Scraping - Data Parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DatesinOffice</th>\n",
       "      <th>DaysInOffice</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>FirstTermAverage</th>\n",
       "      <th>JobApprovalHigh</th>\n",
       "      <th>JobApprovalLow</th>\n",
       "      <th>OverallAverage</th>\n",
       "      <th>Party</th>\n",
       "      <th>PresidentName</th>\n",
       "      <th>SecondTermAverage</th>\n",
       "      <th>StartDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-Present</td>\n",
       "      <td>658</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>45.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>Rep.</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-2017</td>\n",
       "      <td>2922</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>Dem.</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>47</td>\n",
       "      <td>2009-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-2009</td>\n",
       "      <td>2922</td>\n",
       "      <td>2009-01-20</td>\n",
       "      <td>62.2</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>49.4</td>\n",
       "      <td>Rep.</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>36.5</td>\n",
       "      <td>2001-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993-2001</td>\n",
       "      <td>2922</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>49.6</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>55.1</td>\n",
       "      <td>Dem.</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>60.6</td>\n",
       "      <td>1993-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989-1993</td>\n",
       "      <td>1461</td>\n",
       "      <td>1993-01-20</td>\n",
       "      <td>60.9</td>\n",
       "      <td>89</td>\n",
       "      <td>29</td>\n",
       "      <td>60.9</td>\n",
       "      <td>Rep.</td>\n",
       "      <td>George H. W. Bush</td>\n",
       "      <td>-</td>\n",
       "      <td>1989-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DatesinOffice DaysInOffice     EndDate FirstTermAverage JobApprovalHigh  \\\n",
       "0  2017-Present          658                            -            45.0   \n",
       "1     2009-2017         2922  2017-01-20               48              67   \n",
       "2     2001-2009         2922  2009-01-20             62.2              90   \n",
       "3     1993-2001         2922  2001-01-20             49.6              73   \n",
       "4     1989-1993         1461  1993-01-20             60.9              89   \n",
       "\n",
       "  JobApprovalLow OverallAverage Party      PresidentName SecondTermAverage  \\\n",
       "0           35.0           39.5  Rep.    Donald J. Trump                 -   \n",
       "1             40             48  Dem.       Barack Obama                47   \n",
       "2             25           49.4  Rep.     George W. Bush              36.5   \n",
       "3             37           55.1  Dem.       Bill Clinton              60.6   \n",
       "4             29           60.9  Rep.  George H. W. Bush                 -   \n",
       "\n",
       "    StartDate  \n",
       "0  2017-01-20  \n",
       "1  2009-01-20  \n",
       "2  2001-01-20  \n",
       "3  1993-01-20  \n",
       "4  1989-01-20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Declare global variables\n",
    "states = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming', 'District of Columbia']\n",
    "\n",
    "# National unemployement rate by month from 1948 to 2018\n",
    "# Source: https://data.bls.gov/pdq/SurveyOutputServlet\n",
    "national_unemployement_rate = pd.read_csv('data/national_unemployement_1948_2018.csv')\n",
    "\n",
    "# Get the presidental job approval\n",
    "# Source: https://www.gallup.com\n",
    "# https://news.gallup.com/interactives/185273/presidential-job-approval-center.aspx\n",
    "with open('data/all_presidential_job_approval_gallup.json') as f:\n",
    "    presidential_approval = json.load(f)\n",
    "presidential_approval = presidential_approval['AllPresidents']['HistoricalPresident']\n",
    "presidential_approval_df = pd.DataFrame.from_dict([x['PresidentData'] for x in presidential_approval])\n",
    "display(presidential_approval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1952</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n",
       "0  1948  3.4  3.8  4.0  3.9  3.5  3.6  3.6  3.9  3.8  3.7  3.8  4.0\n",
       "1  1949  4.3  4.7  5.0  5.3  6.1  6.2  6.7  6.8  6.6  7.9  6.4  6.6\n",
       "2  1950  6.5  6.4  6.3  5.8  5.5  5.4  5.0  4.5  4.4  4.2  4.2  4.3\n",
       "3  1951  3.7  3.4  3.4  3.1  3.0  3.2  3.1  3.1  3.3  3.5  3.5  3.1\n",
       "4  1952  3.2  3.1  2.9  2.9  3.0  3.0  3.2  3.4  3.1  3.0  2.8  2.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(national_unemployement_rate.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get once the necessary pages\n",
    "presidential_page = requests.get('https://en.wikipedia.org/wiki/United_States_presidential_election')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>president_elected</th>\n",
       "      <th>president_elected_party</th>\n",
       "      <th>can_be_re_elected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1824</td>\n",
       "      <td>John Quincy Adams</td>\n",
       "      <td>DR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1828</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1832</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1836</td>\n",
       "      <td>Martin Van Buren</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1840</td>\n",
       "      <td>William Henry Harrison</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       president_elected president_elected_party  can_be_re_elected\n",
       "0  1824       John Quincy Adams                      DR                  1\n",
       "1  1828          Andrew Jackson                       D                  1\n",
       "2  1832          Andrew Jackson                       D                  0\n",
       "3  1836        Martin Van Buren                       D                  1\n",
       "4  1840  William Henry Harrison                       W                  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of the US presidents\n",
    "president_elected_history = pd.read_csv('data/president_elected_history.csv', sep=';')\n",
    "display(president_elected_history.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 89968: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-06d09f806234>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melections_pages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhouse_elections_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_house_elections_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m national_level_factors = data_df[[\n",
      "\u001b[1;32m<ipython-input-7-06d09f806234>\u001b[0m in \u001b[0;36mextract_house_elections_history\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mlist_of_house_elections_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 89968: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the national level factors\n",
    "Source: https://en.wikipedia.org/wiki/United_States_presidential_election\n",
    "\"\"\"\n",
    "\n",
    "# From a tag, extract the number of seats\n",
    "def extract_seats(tag):\n",
    "    if tag.findAll('b'):\n",
    "        d_seats = tag.b.extract().string\n",
    "    elif tag.sup and tag.sup.decompose():\n",
    "        d_seats = tag.sup.decompose()\n",
    "    elif tag.string is None:\n",
    "        d_seats = tag.text\n",
    "    else:\n",
    "        d_seats = tag.string\n",
    "    return int(d_seats)\n",
    "\n",
    "def extract_seats_change(tag):\n",
    "    if tag.sup:\n",
    "        d_seats_change = tag.text.split('[', 1)[0]\n",
    "    else:\n",
    "        d_seats_change = tag.text\n",
    "    return int(d_seats_change.replace('–', '-'))\n",
    "\n",
    "# Get the house election years\n",
    "def extract_house_elections_history():\n",
    "    house_elections_history = []\n",
    "\n",
    "    # If the file doesn't exist, get the data from the webpage and store the content to a new file\n",
    "    filename = 'data/list_of_house_elections_page.html'\n",
    "    if Path(filename).is_file():\n",
    "        with open(filename) as my_file:\n",
    "            list_of_house_elections_page = my_file.read()\n",
    "    else:\n",
    "        print('no file')\n",
    "        list_of_house_elections_page = requests.get('https://en.wikipedia.org/wiki/List_of_United_States_House_of_Representatives_elections,_1856%E2%80%93present')\n",
    "        with open(filename,'w') as outfile:\n",
    "            outfile.write(list_of_house_elections_page.text)\n",
    "\n",
    "    soup = BeautifulSoup(list_of_house_elections_page, \"html.parser\")\n",
    "\n",
    "    # Find the election years\n",
    "    data = []\n",
    "    elections_pages = []\n",
    "    for t in soup.find_all('a', title=lambda x: x and 'United States House of Representatives elections,' in x):\n",
    "        if len(t.string) == 4:\n",
    "            elections_pages.append({\n",
    "                'year': int(t.string),\n",
    "                'url':'https://en.wikipedia.org'+t.attrs['href']\n",
    "            })\n",
    "            year = int(t.string)+2\n",
    "\n",
    "            cols = t.parent.parent.find_all('td')\n",
    "\n",
    "            # Get the number of Democrat seats\n",
    "            d_seats = extract_seats(cols[1])\n",
    "\n",
    "            # Get the change in the number of Democrat seats\n",
    "            d_seats_change = extract_seats_change(cols[2])\n",
    "\n",
    "            # Get the number of Republican seats\n",
    "            r_seats = extract_seats(cols[3])\n",
    "            \n",
    "            # Get the change in the number of Republican seats\n",
    "            r_seats_change_by_year = extract_seats_change(cols[4])\n",
    "            \n",
    "            #print(1 if year in presidential_years else 0)\n",
    "\n",
    "            idx = (np.abs(president_elected_history['year'].values-year+1)).argmin()\n",
    "            president_can_be_re_elected = president_elected_history['can_be_re_elected'].loc[[idx]].values[0]\n",
    "            president_party = president_elected_history['president_elected_party'].loc[[idx]].values[0]\n",
    "\n",
    "            # Look for president overall job approval average\n",
    "            president_name = president_elected_history['president_elected'].loc[[idx]].values[0]\n",
    "            president_overall_avg_job_approval = presidential_approval_df.loc[presidential_approval_df['PresidentName'] == president_name]['OverallAverage']\n",
    "            president_overall_avg_job_approval = float(president_overall_avg_job_approval.values[0])/100 if president_overall_avg_job_approval.values.size else None\n",
    "            \n",
    "            # Get the national unemployement rate for November\n",
    "            oct_unemployement_rate = national_unemployement_rate.loc[national_unemployement_rate['Year'] == year]['Oct']\n",
    "            \n",
    "            oct_unemployement_rate = oct_unemployement_rate.values[0] if oct_unemployement_rate.values.size else None\n",
    "            \n",
    "            data.append({\n",
    "                'year': year,\n",
    "                'is_presidential_year': 1 if year in president_elected_history['year'].unique() else 0,\n",
    "                'president_party': president_party,\n",
    "                'president_can_be_re_elected': president_can_be_re_elected,\n",
    "                'president_overall_avg_job_approval': president_overall_avg_job_approval,\n",
    "                'oct_unemployement_rate': oct_unemployement_rate,\n",
    "                'last_democrat_seats': d_seats,\n",
    "                'last_republican seats': r_seats,\n",
    "                'last_house_majority': 'R' if d_seats < r_seats else 'D'\n",
    "            })\n",
    "\n",
    "    return data, elections_pages\n",
    "\n",
    "data, house_elections_pages = extract_house_elections_history()\n",
    "data_df = pd.DataFrame(data)\n",
    "national_level_factors = data_df[[\n",
    "    'year', \n",
    "    'is_presidential_year', \n",
    "    'president_party', \n",
    "    'president_can_be_re_elected', \n",
    "    'president_overall_avg_job_approval', \n",
    "    'oct_unemployement_rate',\n",
    "    'last_democrat_seats', \n",
    "    'last_republican seats', \n",
    "    'last_house_majority']]\n",
    "display(national_level_factors.sort_values('year', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the state level factors\n",
    "\"\"\"\n",
    "\n",
    "# Historical presidential election results by state\n",
    "# Source: https://en.wikipedia.org/wiki/List_of_United_States_presidential_election_results_by_state\n",
    "election_results_df = pd.read_csv('data/presidential_election_results_by_state.csv')\n",
    "election_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikipedia.org\n",
    "### Get the House and Senate election result pages for all the available years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the district level factor\n",
    "\"\"\"\n",
    "def get_district_list():\n",
    "    district_list = []\n",
    "    url = 'https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2016'\n",
    "    filename = 'data/wikipedia/all_state_districts_list_page.html'\n",
    "    \n",
    "    # Check if the page has been stored on disk\n",
    "    soup = check_or_save_page(filename, url)\n",
    "    \n",
    "    # Find the districts page links\n",
    "    districts = soup.find_all('a', href=re.compile(r'(.*\\/wiki\\/.* )|(.*_congressional_district)'))\n",
    "    \n",
    "    for district in districts:\n",
    "        if any(substring in district.string for substring in states) \\\n",
    "        and district.string not in district_list \\\n",
    "        and \"'s\" not in district.string \\\n",
    "        and \"12th\" not in district.string \\\n",
    "        and '1st' not in district.string:\n",
    "            district_state = ''\n",
    "            # Get the corresponding state\n",
    "            for state in states:\n",
    "                if state in district.string:\n",
    "                    district_state = state\n",
    "            \n",
    "            # Format the district name\n",
    "            if 'at-large' in district.string:\n",
    "                dist_name = 'At-Large'\n",
    "            else:\n",
    "                # Find the district number\n",
    "                dist_number = [int(s) for s in district.string.split() if s.isdigit()]\n",
    "                if len(dist_number) > 0:\n",
    "                    dist_number = dist_number[0]\n",
    "                    dist_name = 'District {}'.format(dist_number)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            #print(district_state, dist_name)\n",
    "            \n",
    "            district_list.append({\n",
    "                'name': dist_name,\n",
    "                'page_url': 'https://en.wikipedia.org{}'.format(district['href']),\n",
    "                'state': district_state\n",
    "            })\n",
    "            \n",
    "    # Remove duplicate in the list\n",
    "    district_list = [dict(t) for t in {tuple(d.items()) for d in district_list}]\n",
    "    \n",
    "    return district_list\n",
    "\n",
    "def get_wiki_district_pages(districts):\n",
    "    # Get the district pages if they have not been stored on disk yet\n",
    "    for district in districts:\n",
    "        filename = 'data/district_pages/{}.html'.format(district['name'])\n",
    "\n",
    "        # Check if the page has been stored on disk\n",
    "        check_or_save_page(filename, district['page_url'])\n",
    "        \n",
    "def parse_district_house_results(filename, district, state):\n",
    "    undesirable_chars = ['\\*', '%', '\\(incumbent\\)', '\\(inc.\\)', '\\(write-in\\)']\n",
    "    district_house_results = []\n",
    "    with open(filename) as my_file:\n",
    "        soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "        \n",
    "        # Find the election results tables\n",
    "        caption = soup.find_all('caption')\n",
    "        elems = []\n",
    "        for capt in caption:\n",
    "            x = capt.get_text()\n",
    "            if ('United States House of Representatives elections,' in x or\n",
    "                'congressional district election' in x or\n",
    "                'US House election, ' in x or\n",
    "                'Congressional District House Election'\n",
    "            ):\n",
    "                elems.append(capt)\n",
    "\n",
    "        for capt in elems:\n",
    "            # Find the date\n",
    "            match = re.match(r'.*([1-2][0-9]{3})', capt.text)\n",
    "            if match is None:\n",
    "                continue\n",
    "\n",
    "            # Then it found a match!\n",
    "            year = int(match.group(1))\n",
    "            #print(year)\n",
    "\n",
    "            # Get the result table itself\n",
    "            table = capt.find_parent('table')\n",
    "            table_body = table.find('tbody')\n",
    "            rows = table_body.find_all('tr')\n",
    "\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                cols = [ele for ele in cols if ele] # Get rid of empty values\n",
    "\n",
    "                if len(cols) and cols[0] in ['Republican', 'Democratic']:\n",
    "                    print(cols)\n",
    "                    \n",
    "                    percent = np.NaN\n",
    "                    if len(cols) > 3 and cols[3] != 'N/A':\n",
    "                        percent = float(re.sub(\"|\".join(undesirable_chars), \"\", cols[3]))/100\n",
    "                    \n",
    "                    votes = np.NaN\n",
    "                    if len(cols) > 2 and cols[2] == 'N/A':\n",
    "                        votes = np.NaN\n",
    "                    elif len(cols) > 2 and '%' not in cols[2] and cols[2] != '100.00':\n",
    "                        votes = int(cols[2].replace(',', '').replace('.', ''))\n",
    "                    elif len(cols) > 2 and ('%' in cols[2] or cols[2] == '100.00'):\n",
    "                        percent = float(re.sub(\"|\".join(undesirable_chars), \"\", cols[2]))/100\n",
    "                    \n",
    "                    district_house_results.append({\n",
    "                        'year': year,\n",
    "                        'candidate_party': 'R' if cols[0] == \"Republican\" else 'D',\n",
    "                        'candidate_name': re.sub(\"|\".join(undesirable_chars), \"\", cols[1]),\n",
    "                        'votes': votes,\n",
    "                        'percent': percent\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(district_house_results)\n",
    "    \n",
    "def get_district_level_factors(district):\n",
    "    state = districts_df.loc[districts_df['name'] == district]['state'].values[0]\n",
    "    dist_level_factors = []\n",
    "    # Get the page of the district\n",
    "    html_filename = 'data/district_pages/{}.html'.format(district)\n",
    "    json_filename = 'data/district_pages/{}.json'.format(district)\n",
    "    \n",
    "    # If there is no already formated data, get them from the corresponding Wikipedia page\n",
    "    if Path(json_filename).is_file() is False:\n",
    "        district_house_results = parse_district_house_results(html_filename, district, state)\n",
    "        display(district_house_results)\n",
    "    else:\n",
    "        print('get from json')\n",
    "        district_house_results = pd.read_json(json_filename)\n",
    "        display(district_house_results)\n",
    "        \n",
    "    # Now, for each year\n",
    "    for year in district_house_results['year'].unique():\n",
    "        # If there is more than 1 candidate this year\n",
    "        # Get the current year\n",
    "        if len(district_house_results.loc[district_house_results['year'] == year]) > 1:\n",
    "            curr_year_idx = district_house_results.loc[district_house_results['year'] == year]['votes'].idxmax()\n",
    "            curr_year = district_house_results.loc[[curr_year_idx]]\n",
    "        else:\n",
    "            curr_year = district_house_results        \n",
    "        \n",
    "        # Get previous year\n",
    "        prev_year = district_house_results.loc[district_house_results['year'] == year-2]\n",
    "\n",
    "        if prev_year.empty is False:\n",
    "            # If there is more than 1 candidate the previous year\n",
    "            if len(prev_year) > 1:\n",
    "                prev_year_winner_idx = prev_year['votes'].idxmax()\n",
    "                prev_year_winner = prev_year.loc[[prev_year_winner_idx]]\n",
    "            else:\n",
    "                prev_year_winner = prev_year\n",
    "\n",
    "            # Get the incumbent name\n",
    "            incumbent = prev_year_winner['candidate_name'].values[0]\n",
    "\n",
    "            # Get the elections previously won by the incumbent\n",
    "            incumbent_history = district_house_results.loc[\n",
    "                (district_house_results['candidate_name'] == incumbent) &\n",
    "                (district_house_results['year'] < year)\n",
    "            ]\n",
    "\n",
    "            incubent_first_elected_idx = incumbent_history['year'].idxmin()\n",
    "            incubent_first_elected = incumbent_history.loc[[incubent_first_elected_idx]]['year'].values[0]\n",
    "            incubent_is_candidate = curr_year.loc[curr_year['candidate_name'] == incumbent].empty\n",
    "\n",
    "            dist_data = {\n",
    "                'year': year,\n",
    "                'state': state,\n",
    "                'district': district,\n",
    "                'incumbent': incumbent,\n",
    "                'incumbent_party': 'R' if prev_year_winner['candidate_party'].values[0] == \"Republican\" else 'D',\n",
    "                'incumbent_count_victories': len(incumbent_history),\n",
    "                'incumbent_first_elected': incubent_first_elected,\n",
    "                'incumbent_running_re_election': 0 if incubent_is_candidate else 1,\n",
    "                'candidate_elected_party': curr_year['candidate_party'].values[0]\n",
    "            }\n",
    "\n",
    "            dist_level_factors.append(dist_data)\n",
    "        else:\n",
    "            print('yop')\n",
    "            dist_data = {\n",
    "                'year': year,\n",
    "                'state': state,\n",
    "                'district': district,\n",
    "                'incumbent': np.NaN,\n",
    "                'incumbent_party': np.NaN,\n",
    "                'incumbent_count_victories': np.NaN,\n",
    "                'incumbent_first_elected': np.NaN,\n",
    "                'incumbent_running_re_election': np.NaN,\n",
    "                'candidate_elected_party': curr_year['candidate_party'].values[0]\n",
    "            }\n",
    "            dist_level_factors.append(dist_data)\n",
    "\n",
    "    return dist_level_factors\n",
    "\n",
    "#for district in ['Alabama 1', 'Alabama 2']:\n",
    "#for district in ['Arkansas 1']:\n",
    "#    district_level_factors = get_district_level_factors(district)\n",
    "#    display(pd.DataFrame(district_level_factors).sort_values('year', ascending=True))\n",
    "#    #display(district_level_factors)\n",
    "\n",
    "def get_wiki_districts_house_results(districts_list):\n",
    "    candidate_results = []\n",
    "    wiki_undesirable_chars = [\n",
    "        '\\*', '%', '\\(Incumbent\\)', '\\(incumbent\\)', '\\(inc.\\)', '\\(write-in\\)', \n",
    "        '\\(as a write-in\\)'\n",
    "    ]\n",
    "    for district in districts_list:\n",
    "        # To remove\n",
    "        #if district['state'] != 'Texas' or district['name'] != 'District 17':\n",
    "        #if district['state'] != 'Wyoming':\n",
    "        #    continue\n",
    "        \n",
    "        print('Will get results for house/{}/{}.html'.format(district['state'], district['name']))\n",
    "        print('Source: {}'.format(district['page_url']))\n",
    "        \n",
    "        # In some cases, the wikipedia page is too messy to crawl\n",
    "        # So I manually gather the informations into a json file\n",
    "        # If this file exist, it will be prefered\n",
    "        json_filename = 'data/wikipedia/house/{}/{}.json'.format(district['state'], district['name'])\n",
    "        if Path(json_filename).is_file() is True:\n",
    "            print('Data are store in a formated JSON')\n",
    "            continue\n",
    "        \n",
    "        # Create the directories if necessary\n",
    "        if not os.path.exists('data/wikipedia/house'):\n",
    "            os.makedirs('data/wikipedia/house')\n",
    "        if not os.path.exists('data/wikipedia/house/{}'.format(district['state'])):\n",
    "            os.makedirs('data/wikipedia/house/{}'.format(district['state']))\n",
    "            \n",
    "        filename = 'data/wikipedia/house/{}/{}.html'.format(district['state'], district['name'])\n",
    "        \n",
    "        # Check if the page has been stored on disk\n",
    "        soup = check_or_save_page(filename, district['page_url'])\n",
    "        \n",
    "        # Find the results tables\n",
    "        caption = soup.find_all('caption')\n",
    "        tables = []\n",
    "        for capt in caption:\n",
    "            x = capt.get_text()\n",
    "            if ('United States House of Representatives elections,' in x or\n",
    "                'congressional district election' in x or\n",
    "                'US House election, ' in x or\n",
    "                'Congressional District House Election'\n",
    "            ):\n",
    "                # print(capt)\n",
    "                table = capt.find_parent('table')\n",
    "                tables.append(table)\n",
    "        \n",
    "        # For each result table, extract the results\n",
    "        for table in tables:\n",
    "            # Get the year\n",
    "            table_title = table.find('caption')\n",
    "            \n",
    "            # If this is a table about a special election, skip it\n",
    "            if 'Special' in table_title.text:\n",
    "                continue\n",
    "            \n",
    "            year_match = re.match(r'.*([1-2][0-9]{3})', table_title.text)\n",
    "            \n",
    "            # If there is no year match, then this table isn't of interest\n",
    "            if year_match is None:\n",
    "                continue\n",
    "            \n",
    "            year = int(year_match.group(1))\n",
    "            # print(year)\n",
    "            \n",
    "            # Get the result table itself\n",
    "            rows = table.find('tbody').find_all('tr')\n",
    "            candidate_rows = []\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                # If all the values of the cols are empty strings, continue\n",
    "                if all(v is '' for v in cols):\n",
    "                    continue\n",
    "                    \n",
    "                # print(cols)\n",
    "                \n",
    "                # If this row contains a candidate results\n",
    "                if len(cols) > 2 and cols[1] in ['Republican', 'Democratic']:\n",
    "                    # print(cols)\n",
    "                    \n",
    "                    party = 'R' if cols[1] == 'Republican' else 'D'\n",
    "                    name = cols[2]\n",
    "                    votes = int(cols[3].replace(',', '').replace('[8]', '').replace('c', '').replace('.', '').replace(' ', '')) if cols[3] != '' else np.NaN\n",
    "                    percent = float(cols[4].replace('%', '')) if cols[4] != '' else np.NaN\n",
    "                    \n",
    "                    candidate_rows.append({\n",
    "                        'year': year,\n",
    "                        'state': district['state'],\n",
    "                        'district': district['name'],\n",
    "                        'is_incumbent': np.NaN,\n",
    "                        'name': name,\n",
    "                        'party': party,\n",
    "                        'percent': percent,\n",
    "                        'votes': votes,\n",
    "                        'won': 0\n",
    "                    })\n",
    "                    \n",
    "            # If we found no candidate data, continue\n",
    "            if len(candidate_rows) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Enrich the candidates data\n",
    "            max_percent = max([x['percent'] for x in candidate_rows])\n",
    "            for candidate in candidate_rows:\n",
    "                # Check if the candidate won the elections\n",
    "                if candidate['percent'] == max_percent:\n",
    "                    candidate['won'] = 1\n",
    "                    \n",
    "                # Check if we can determine if the candidate is an incumbent\n",
    "                if '(inc.)' in candidate['name'] or '(incumbent)' in candidate['name'] or '(Incumbent)' in candidate['name']:\n",
    "                    candidate['is_incumbent'] = 1\n",
    "\n",
    "                # Clean the candidate name\n",
    "                candidate['name'] = re.sub(\"|\".join(wiki_undesirable_chars), \"\", candidate['name'])\n",
    "                    \n",
    "                candidate_results.append(candidate)\n",
    "                \n",
    "            # If we found that one of the candidates is an incumbent, the others are sets to 0\n",
    "            max_incumbent = max([x['is_incumbent'] for x in candidate_rows])\n",
    "            #print(type(max_incumbent))\n",
    "            if max_incumbent == 1:\n",
    "                for candidate in candidate_rows:\n",
    "                    candidate['is_incumbent'] = 0 if candidate['is_incumbent'] != 1 else 1\n",
    "\n",
    "    return candidate_results\n",
    "\n",
    "districts_list = get_district_list()\n",
    "# districts_df = pd.DataFrame(districts_list)\n",
    "# display(districts_df.loc[districts_df['state'] == 'Wyoming'])\n",
    "\n",
    "wiki_house_history = get_wiki_districts_house_results(districts_list)\n",
    "# Store in disk\n",
    "wiki_house_history_df = pd.DataFrame(wiki_house_history)\n",
    "wiki_house_history_df.to_csv('data/wikipedia/house_results.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now have on disk ALL the available historical district results from Wikipedia**\n",
    "\n",
    "Lets take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/wikipedia/house_results.csv', index_col=0)\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ballotpedia.org\n",
    "\n",
    "So far so good but the 2018 results are missing on Wikipedia and the available data are not always exhaustives. So I decided to get the same informations from a different source: Ballotpedia.  \n",
    "Here we have the complete 2018 results as well as historical date from 2012.  \n",
    "Note that the incumbent information is consistent.  \n",
    "\n",
    "### Get the House and Senate election result pages for all the available years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_senate_state_list():\n",
    "    house_state_list = []\n",
    "    senate_state_list = []\n",
    "    filename = 'data/ballotpedia/house_state_list_src.html'\n",
    "    url = 'https://ballotpedia.org/U.S._House_battlegrounds,_2018'\n",
    "    \n",
    "    # Check if the page has been stored on disk\n",
    "    soup = check_or_save_page(filename, url)\n",
    "    \n",
    "    # Find the list of the U.S. Senate Elections by State (2018) pages\n",
    "    table = soup.find('table', { 'class': 'infobox' })\n",
    "    for link in table.find_all('a', href=lambda x: x and '/United_States_Senate_election_in_' in x):\n",
    "        senate_state_list.append({\n",
    "            'state': link.text,\n",
    "            'url': 'https://ballotpedia.org{}'.format(link['href'])\n",
    "        })\n",
    "\n",
    "    # Find the list of the U.S. House Elections by State (2018) pages\n",
    "    table = soup.find('table', { 'class': 'infobox' })\n",
    "    for link in table.find_all('a', href=lambda x: x and (\n",
    "        '/United_States_House_of_Representatives_election_in_' in x or\n",
    "        '/United_States_House_of_Representatives_elections_in_' in x\n",
    "    )):\n",
    "        house_state_list.append({\n",
    "            'state': link.text,\n",
    "            'url': 'https://ballotpedia.org{}'.format(link['href'])\n",
    "        })\n",
    "\n",
    "    return house_state_list, senate_state_list\n",
    "\n",
    "def get_district_pages(dict_page_url, year, state, district):\n",
    "    \"\"\" \n",
    "        Recursively get all available previous election result pages\n",
    "        for a given district\n",
    "    \"\"\"\n",
    "    print('Will get house/{}/{}/{}.html'.format(state, district, year))\n",
    "    # Create the directories if necessary\n",
    "    if not os.path.exists('data/ballotpedia/house/'):\n",
    "        os.makedirs('data/ballotpedia/house/')\n",
    "    if not os.path.exists('data/ballotpedia/house/{}'.format(state)):\n",
    "        os.makedirs('data/ballotpedia/house/{}'.format(state))\n",
    "    if not os.path.exists('data/ballotpedia/house/{}/{}'.format(state, district)):\n",
    "        os.makedirs('data/ballotpedia/house/{}/{}'.format(state, district))\n",
    "    \n",
    "    filename = 'data/ballotpedia/house/{}/{}/{}.html'.format(state, district, year)\n",
    "    dict_soup = check_or_save_page(filename, dict_page_url)\n",
    "    \n",
    "    # Check if there is a link to a previous electoral year for this state\n",
    "    table = dict_soup.find('table', { 'class': 'infobox' })\n",
    "    div = table.find('div', style=lambda x: x and '#A3B1BF' in x and 'float:left;' in x)\n",
    "            \n",
    "    # If there is one\n",
    "    if div is not None:\n",
    "        # Extract the link election year\n",
    "        prev_year = int(re.match(r'.*([1-2][0-9]{3})', div.text).group(1))\n",
    "        \n",
    "        if prev_year < year:                \n",
    "            # Get the link to this disctict House election results parge\n",
    "            link = div.find('a')\n",
    "            #print(link['href'])\n",
    "\n",
    "            # Get this page\n",
    "            url = 'https://ballotpedia.org{}'.format(link['href'])\n",
    "            get_district_pages(url, prev_year, state, district)\n",
    "\n",
    "def get_house_senate_state_districts_list(house_state_list):\n",
    "    start_year = 2018\n",
    "    state_district_list = []\n",
    "    for house_state in house_state_list:\n",
    "        # To remove\n",
    "        #if house_state['state'] != 'Maryland':\n",
    "        #    continue\n",
    "\n",
    "        filename = 'data/ballotpedia/2018_house_{}.html'.format(house_state['state'])\n",
    "        \n",
    "        # Check if the page has been stored on disk\n",
    "        soup = check_or_save_page(filename, house_state['url'])\n",
    "        #print(soup)\n",
    "        \n",
    "        # Get the district page links\n",
    "        table = soup.find('table', { 'class': 'infobox' })\n",
    "        \n",
    "        links = table.find_all('a', href=lambda x: x and (\n",
    "            '_Congressional_District_election,_' in x\n",
    "        ))\n",
    "        \n",
    "        if len(links) == 0:\n",
    "            title = soup.find('b', text=lambda x : x and 'District Pages' in x)\n",
    "            links = title.parent.parent.find_all('a', href=lambda x: x and (\n",
    "                '_Congressional_District_election,_' in x\n",
    "            ))\n",
    "\n",
    "        for link in links:\n",
    "            print(link.text)\n",
    "            url = 'https://ballotpedia.org{}'.format(link['href'])\n",
    "            state_district_list.append({\n",
    "                'state': house_state['state'],\n",
    "                'district': link.text\n",
    "            })\n",
    "            #print(' |-', url)\n",
    "\n",
    "            # Get the page\n",
    "            get_district_pages(url, start_year, house_state['state'], link.text)\n",
    "            \n",
    "    return state_district_list\n",
    "\n",
    "house_state_list, senate_state_list = get_house_senate_state_list()\n",
    "state_district_list = get_house_senate_state_districts_list(house_state_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the House election results for every districts and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_district_data(state_district_list):\n",
    "    results = []\n",
    "    undesirable_chars = ['\\*', '%', 'Incumbent', '\\(D\\)', '\\(R\\)']\n",
    "    for item in state_district_list:\n",
    "        # To remove\n",
    "        #if item['state'] != 'New Hampshire' or item['district'] != 'District 2':\n",
    "        #if item['state'] != 'Wyoming':\n",
    "        #    continue\n",
    "\n",
    "        # Get the pages\n",
    "        directory = 'data/ballotpedia/house/{}/{}'.format(item['state'], item['district'])\n",
    "        files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        \n",
    "        # For each year, get the district data\n",
    "        for file in files:\n",
    "            # Extract the year\n",
    "            year = int(re.match(r'.*([1-2][0-9]{3})', file).group(1))\n",
    "            candidate_rows = []\n",
    "            \n",
    "            # To remove\n",
    "            #if year != 2018:\n",
    "            #    continue\n",
    "            \n",
    "            # Get the page content\n",
    "            filename = 'data/ballotpedia/house/{}/{}/{}'.format(item['state'], item['district'], file)\n",
    "            with open(filename) as my_file:\n",
    "                soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "            \n",
    "            # The 2018 pages requires a different approach\n",
    "            if year == 2018:\n",
    "                #print(2018)\n",
    "                # Find the result table\n",
    "                table = soup.find('table',  { 'class': 'results_table' })\n",
    "                rows = table.find_all('tr')\n",
    "                \n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [ele.text.strip() for ele in cols]\n",
    "                    cols = [ele for ele in cols if ele] # Get rid of empty values\n",
    "                    \n",
    "                    # Check if is incumbant\n",
    "                    incumbent = 1 if row.find('b') and row.find('b').find('u') else 0\n",
    "                    #print(cols)\n",
    "                    if len(cols) == 4 and cols[0] == '✔':\n",
    "                        is_winner = 1\n",
    "                        name = cols[1] +' Incumbent' if incumbent == 1 else cols[1]\n",
    "                        percent = cols[2] if len(cols) > 1 else np.NaN\n",
    "                        votes = cols[3] if len(cols) > 2 else np.NaN\n",
    "                        party = 'Democratic' if '(D)' in cols[1] else 'Republican'\n",
    "                        candidate_rows.append([party, name, percent, votes, is_winner])\n",
    "                        \n",
    "                    elif len(cols) == 3 and '(D)' in cols[0] or '(R)' in cols[0]:\n",
    "                        is_winner = 0\n",
    "                        name = cols[0] +' Incumbent' if incumbent == 1 else cols[0]\n",
    "                        percent = cols[1] if len(cols) > 1 else np.NaN\n",
    "                        \n",
    "                        votes = cols[2] if len(cols) > 2 else np.NaN\n",
    "                        if len(cols) > 1:\n",
    "                            party = 'Democratic' if '(D)' in cols[0] else 'Republican'\n",
    "                        else:\n",
    "                            party = np.NaN\n",
    "                            \n",
    "                        candidate_rows.append([party, name, percent, votes, is_winner])\n",
    "                \n",
    "            else:            \n",
    "                # Find the result table\n",
    "                th = soup.find('th', colspan='5', style=lambda x: x and 'background-color:#444' in x)\n",
    "                table = th.find_parent('table')\n",
    "                #table_body = table.find('tbody')\n",
    "                rows = table.find_all('tr')\n",
    "                #print(rows)\n",
    "\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [ele.text.strip() for ele in cols]\n",
    "                    cols = [ele for ele in cols if ele] # Get rid of empty values\n",
    "\n",
    "                    # Ignore the rows not about the candidates\n",
    "                    if 'Republican' not in cols and not 'Democratic' in cols:\n",
    "                        continue\n",
    "\n",
    "                    # Check if the candidate won the elections\n",
    "                    is_winner = 1 if row.find('a', title=\"Won\") else 0\n",
    "                    cols.append(is_winner)\n",
    "                    candidate_rows.append(cols)\n",
    "                    \n",
    "            # If there was only one candidate\n",
    "            if len(candidate_rows) == 1:\n",
    "                if type(candidate_rows[0][3]) is int:\n",
    "                    candidate_rows[0].append(candidate_rows[0][3])\n",
    "                    candidate_rows[0][3] = np.NaN\n",
    "\n",
    "            for candidate in candidate_rows:\n",
    "                #print(year, item['district'], candidate)\n",
    "                \n",
    "                # Get and format the candidate party\n",
    "                candidate_party = 'R' if candidate[0] == 'Republican' else 'D'\n",
    "                \n",
    "                # Get and clean the candidate name\n",
    "                candidate_name = re.sub(\"|\".join(undesirable_chars), \"\", candidate[1]).rstrip()\n",
    "                \n",
    "                # Get and clean the candidate percent\n",
    "                if type(candidate[2]) is str:\n",
    "                    candidate_percent = float(candidate[2].replace('%', ''))\n",
    "                else:\n",
    "                    candidate_percent = candidate[2]\n",
    "                \n",
    "                # Get and clean the candidate vote\n",
    "                if type(candidate[3]) is str:\n",
    "                    candidate_vote = int(candidate[3].replace(',', ''))\n",
    "                else:\n",
    "                    candidate_vote = candidate[3]\n",
    "                \n",
    "                # Determine whether or not the candidate is incumbent\n",
    "                candidate_is_incumbent = 1 if 'Incumbent' in candidate[1] else 0\n",
    "                \n",
    "                results.append({\n",
    "                    'year': year,\n",
    "                    'state': item['state'],\n",
    "                    'district': item['district'] if item['district'] != 'General election' else 'At-Large',\n",
    "                    'name': candidate_name,\n",
    "                    'party': candidate_party,\n",
    "                    'percent': candidate_percent,\n",
    "                    'votes': candidate_vote,\n",
    "                    'is_incumbent': candidate_is_incumbent,\n",
    "                    'won': candidate[4]\n",
    "                })\n",
    "                \n",
    "                #print(results)\n",
    "                #print('')\n",
    "\n",
    "        #soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "        #print(soup)\n",
    "    return results\n",
    "\n",
    "ballo_house_history = extract_district_data(state_district_list)\n",
    "\n",
    "# Store on disk\n",
    "ballo_house_history_df = pd.DataFrame(ballo_house_history)\n",
    "ballo_house_history_df.to_csv('data/ballotpedia/ballo_results.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the data from wikipedia.org and  ballotpedia.org\n",
    "\n",
    "Now we have two dataset with the same columns and some overlaping data. Its time to merge them.  \n",
    "It appears that the data from ballotpedia.org are more consistent so we will favor them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>is_incumbent</th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>percent</th>\n",
       "      <th>state</th>\n",
       "      <th>votes</th>\n",
       "      <th>won</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>106059.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andy Wilson</td>\n",
       "      <td>D</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>25984.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>168501.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dwight Fullingim</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>58030.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>92811.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      district  is_incumbent              name party  percent  state  \\\n",
       "1  District 19           NaN  Randy Neugebauer     R     78.0  Texas   \n",
       "2  District 19           NaN       Andy Wilson     D     19.0  Texas   \n",
       "3  District 19           NaN  Randy Neugebauer     R     72.0  Texas   \n",
       "4  District 19           NaN  Dwight Fullingim     D     25.0  Texas   \n",
       "5  District 19           NaN  Randy Neugebauer     R     68.0  Texas   \n",
       "\n",
       "      votes  won  year  \n",
       "1  106059.0    1  2010  \n",
       "2   25984.0    0  2010  \n",
       "3  168501.0    1  2008  \n",
       "4   58030.0    0  2008  \n",
       "5   92811.0    1  2006  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ballo_df = pd.read_csv('data/ballotpedia/ballo_results.csv', index_col=0)\n",
    "wikipedia_df = pd.read_csv('data/wikipedia/house_results.csv', index_col=0)\n",
    "\n",
    "merged_df =  pd.concat([wikipedia_df.loc[wikipedia_df['year'] < 2012], ballo_df])\n",
    "display(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imput and derive from the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this data, we can create new predictors: \n",
    "\n",
    "- Impute the missing data for `is_incumbent`\n",
    "- First time the incumbent has been elected\n",
    "- Number of incumbents victories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN is_incumbent values before: 2748\n",
      "NaN is_incumbent values after: 118\n"
     ]
    }
   ],
   "source": [
    "derived_df = merged_df.copy()\n",
    "derived_df = derived_df.sort_values(by=['year'])\n",
    "\n",
    "# Number of NaN values for the `is_incumbent` col\n",
    "print('NaN is_incumbent values before:', derived_df['is_incumbent'].isna().sum())\n",
    "\n",
    "def check_if_is_incumbent(row):\n",
    "    is_incumbent = row['is_incumbent']\n",
    "\n",
    "    # Check if there is a previous election for this state, district and candidate\n",
    "    prev_year = row['year'] - 2\n",
    "    prev_year_row = derived_df.loc[(derived_df['state'] == row['state']) & (derived_df['district'] == row['district']) & (derived_df['name'] == row['name']) & (derived_df['year'] == prev_year)]\n",
    "\n",
    "    # If the row has NaN for the col `is_incumbent` and the candidate won the last election\n",
    "    if np.isnan(row['is_incumbent']) and prev_year_row.empty is False and prev_year_row['won'].values[0] == 1:\n",
    "        is_incumbent = 1\n",
    "    # If the candidate lose the last elections, it is likely he isn't the incumbent\n",
    "    elif np.isnan(row['is_incumbent']) and prev_year_row.empty is False and prev_year_row['won'].values[0] == 0:\n",
    "        is_incumbent\n",
    "    # If the candidate didn't participate to the last election, \n",
    "    # we can safely assume he isn't the incumbent\n",
    "    elif np.isnan(row['is_incumbent']) and prev_year_row.empty:\n",
    "        is_incumbent = 0\n",
    "        \n",
    "    return is_incumbent\n",
    "\n",
    "# Check if the candidate has already been elected the past year (and so is an incumbent)\n",
    "derived_df['is_incumbent'] = derived_df.apply(check_if_is_incumbent, axis=1)\n",
    "\n",
    "print('NaN is_incumbent values after:', derived_df['is_incumbent'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gain the `is_incumbent` information for 2630 rows. 118 remains NaN.  \n",
    "Now, we will add a new column to know the year of the first election the candidate won:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_year_elected(row):\n",
    "    first_elected = np.NaN\n",
    "    # Get the first year the candidate has been elected (if exist)\n",
    "    victories = derived_df.loc[(derived_df['state'] == row['state']) & (derived_df['district'] == row['district']) & (derived_df['name'] == row['name']) & (derived_df['won'] == 1)]\n",
    "\n",
    "    if victories.empty is False:\n",
    "        first_elected = victories['year'].min()\n",
    "        \n",
    "    return first_elected\n",
    "\n",
    "derived_df['first_time_elected'] = derived_df.apply(get_first_year_elected, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to count the number of victories of each candidate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_victories(row):\n",
    "    count_victories = 0\n",
    "    victories = derived_df.loc[(derived_df['state'] == row['state']) & (derived_df['district'] == row['district']) & (derived_df['name'] == row['name']) & (derived_df['won'] == 1)]\n",
    "    \n",
    "    if victories.empty is False:\n",
    "        count_victories = len(victories)\n",
    "    \n",
    "    return count_victories\n",
    "    \n",
    "derived_df['count_victories'] = derived_df.apply(count_victories, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(derived_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also add the **unemployement rate** at the district level when available, else, at the national level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_district_number(row):\n",
    "    district = row['district']\n",
    "    \n",
    "    p = re.compile(\"District (.*) \\(\")\n",
    "    dist = p.search(row['district']).group(1)\n",
    "    \n",
    "    if dist == '(at Large)':\n",
    "        district = 'At-Large'\n",
    "    else:\n",
    "        district = 'District {}'.format(dist)\n",
    "    \n",
    "    return district\n",
    "\n",
    "def get_state_dist_unemployement(row):\n",
    "    unemployement_rate = np.NaN\n",
    "    \n",
    "    # Find the corresponding unemployement rate\n",
    "    unemp_row = unemp_df.loc[(unemp_df['state'] == row['state']) & \\\n",
    "                             (unemp_df['district'] == row['district']) & \\\n",
    "                             (unemp_df['year'] == row['year'])]\n",
    "\n",
    "    if unemp_row.empty is False:\n",
    "        unemployement_rate = unemp_row['unemp_rate_16'].values[0]\n",
    "    else:\n",
    "        # Use the national unemployement rate of October instead\n",
    "        nat_oct_unemployement_rate = national_unemployement_rate.loc[national_unemployement_rate['Year'] == row['year']]['Oct']\n",
    "        unemployement_rate = np.NaN if nat_oct_unemployement_rate.empty else nat_oct_unemployement_rate.values[0]\n",
    "        \n",
    "    return unemployement_rate\n",
    "\n",
    "augmented_df = derived_df.copy()\n",
    "\n",
    "unemp_df = pd.read_csv('data/unemployment/unemp_2012_2017.csv',sep=';')\n",
    "unemp_df['state'] = unemp_df['state'].str.rsplit(',').str[-1].str.strip()\n",
    "unemp_df['district'] = unemp_df.apply(get_district_number, axis=1)\n",
    "\n",
    "augmented_df['unemployement_rate'] = augmented_df.apply(get_state_dist_unemployement, axis=1)\n",
    "\n",
    "display(augmented_df.loc[augmented_df['state'] == 'Alabama'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundraising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fund = pd.read_csv('data/Fundraising/followthemoney_2009-2018.csv')\n",
    "\n",
    "df_fund['state_abbr']=df_fund['Office_Sought'].str.split(' ', expand=True)[3]\n",
    "df_fund['district']=df_fund['Office_Sought'].str.split(' ', expand=True)[4].astype(int)\n",
    "df_fund['district']='District '+df_fund['district'].astype(str)\n",
    "df_fund['General_Party']=df_fund['General_Party'].str.slice(0,1) #['D', 'R', 'T', 'U']\n",
    "\n",
    "states = pd.read_csv('data/states.csv')\n",
    "\n",
    "df_fund=df_fund.join(states.set_index('Abbreviation'), on='state_abbr')\n",
    "df_fund_grouped=df_fund.groupby(['Election_Year:id', 'State', 'district', 'General_Party'])['Total_$'].sum().reset_index(drop=False)\n",
    "\n",
    "idx = df_fund_grouped.groupby(['Election_Year:id', 'State', 'district'])['Total_$'].transform(max) == df_fund_grouped['Total_$']\n",
    "\n",
    "df_fund_rich_party=df_fund_grouped[idx]\n",
    "df_fund_rich_party.columns=['year', 'state', 'district', 'rich party', 'Total_$']\n",
    "df_fund_rich_party=df_fund_rich_party.drop('Total_$', axis=1)\n",
    "\n",
    "augmented_df=augmented_df.join(df_fund_rich_party.set_index(['year', 'state', 'district']), on=['year', 'state', 'district']).copy()\n",
    "augmented_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also add the following national level factors:  \n",
    "\n",
    "- is_presidential_year: 1 if Yes, 0 if No\n",
    "- president_can_be_re_elected: Can the president stand for re-election ? 1 = Yes, 0 = No  \n",
    "- president_party: D or R\n",
    "- president_overall_avg_job_approval: Only available from 1953 to 2018\n",
    "- last_D_house_seats: # of Democrat seats at the last elections\n",
    "- last_R_house_seats: # of Republican seats at the last elections\n",
    "- last_house_majority: Which party had the majority at the last House elections. D or R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "(\"name 'national_level_factors' is not defined\", 'occurred at index 1963')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5f1cf18e301b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# is_presidential_year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mnat_augmented_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'is_presidential_year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnat_augmented_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_is_presidential_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m# president_can_be_re_elected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6002\u001b[0m                          \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6003\u001b[0m                          kwds=kwds)\n\u001b[1;32m-> 6004\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5f1cf18e301b>\u001b[0m in \u001b[0;36madd_is_presidential_year\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_is_presidential_year\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnational_level_factors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnational_level_factors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'is_presidential_year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: (\"name 'national_level_factors' is not defined\", 'occurred at index 1963')"
     ]
    }
   ],
   "source": [
    "nat_augmented_df = augmented_df.copy()\n",
    "\n",
    "def add_is_presidential_year(row):\n",
    "    result = np.NaN\n",
    "    df = national_level_factors.loc[national_level_factors['year'] == row['year'], 'is_presidential_year']\n",
    "    \n",
    "    if df.empty is False:\n",
    "        result = df.values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def add_president_can_be_re_elected(row):\n",
    "    # idx = (np.abs(president_elected_history['year'].values-row['year']+1)).argmin()\n",
    "    # return president_elected_history['can_be_re_elected'].loc[[idx]].values[0]\n",
    "    result = np.NaN\n",
    "    df = national_level_factors.loc[national_level_factors['year'] == row['year'], 'president_can_be_re_elected']\n",
    "    \n",
    "    if df.empty is False:\n",
    "        result = df.values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def add_president_party(row):\n",
    "    # idx = (np.abs(president_elected_history['year'].values-row['year']+1)).argmin()\n",
    "    # return president_elected_history['president_elected_party'].loc[[idx]].values[0]\n",
    "    result = np.NaN\n",
    "    df = national_level_factors.loc[national_level_factors['year'] == row['year'], 'president_party']\n",
    "    \n",
    "    if df.empty is False:\n",
    "        result = df.values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def add_president_overall_avg_job_approval(row):\n",
    "    # idx = (np.abs(president_elected_history['year'].values-row['year']+1)).argmin()\n",
    "    # president_name = president_elected_history['president_elected'].loc[[idx]].values[0]\n",
    "    # president_overall_avg_job_approval = presidential_approval_df.loc[presidential_approval_df['PresidentName'] == president_name]['OverallAverage']\n",
    "    # return float(president_overall_avg_job_approval.values[0])/100 if president_overall_avg_job_approval.values.size else np.NaN\n",
    "    result = np.NaN\n",
    "    df = national_level_factors.loc[national_level_factors['year'] == row['year'], 'president_overall_avg_job_approval']\n",
    "    \n",
    "    if df.empty is False:\n",
    "        result = df.values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def add_last_D_house_seats(row):\n",
    "    result = np.NaN\n",
    "    df = national_level_factors.loc[national_level_factors['year'] == row['year'], 'last_democrat_seats']\n",
    "    \n",
    "    if df.empty is False:\n",
    "        result = df.values[0]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "def add_last_R_house_seats(row):\n",
    "    result = np.NaN\n",
    "    df = national_level_factors.loc[national_level_factors['year'] == row['year'], 'last_republican seats']\n",
    "    \n",
    "    if df.empty is False:\n",
    "        result = df.values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def add_last_house_majority(row):\n",
    "    result = np.NaN\n",
    "    df = national_level_factors.loc[national_level_factors['year'] == row['year'], 'last_house_majority']\n",
    "    \n",
    "    if df.empty is False:\n",
    "        result = df.values[0]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# is_presidential_year\n",
    "nat_augmented_df['is_presidential_year'] = nat_augmented_df.apply(add_is_presidential_year, axis=1)\n",
    "\n",
    "# president_can_be_re_elected\n",
    "nat_augmented_df['president_can_be_re_elected'] = nat_augmented_df.apply(add_president_can_be_re_elected, axis=1)\n",
    "\n",
    "# president_party\n",
    "nat_augmented_df['president_party'] = nat_augmented_df.apply(add_president_party, axis=1)\n",
    "\n",
    "# president_overall_avg_job_approval\n",
    "nat_augmented_df['president_overall_avg_job_approval'] = nat_augmented_df.apply(add_president_overall_avg_job_approval, axis=1)\n",
    "\n",
    "# last_D_house_seats\n",
    "nat_augmented_df['last_D_house_seats'] = nat_augmented_df.apply(add_last_D_house_seats, axis=1)\n",
    "\n",
    "# last_R_house_seats\n",
    "nat_augmented_df['last_R_house_seats'] = nat_augmented_df.apply(add_last_R_house_seats, axis=1)\n",
    "\n",
    "# last_house_majority\n",
    "nat_augmented_df['last_house_majority'] = nat_augmented_df.apply(add_last_house_majority, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(nat_augmented_df.loc[nat_augmented_df['year'] == 1958].head())\n",
    "#display(nat_augmented_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_level_factors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
