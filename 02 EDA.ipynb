{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasummary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9974, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get the data extracted from different sources\n",
    "house_df = pd.read_csv('data/ready_to_use_dataset.csv')\n",
    "house_df = house_df.drop_duplicates(['year', 'state', 'district', 'name'])\n",
    "display(house_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "district                               object\n",
       "is_incumbent                          float64\n",
       "name                                   object\n",
       "party                                  object\n",
       "percent                               float64\n",
       "state                                  object\n",
       "votes                                 float64\n",
       "won                                     int64\n",
       "year                                    int64\n",
       "first_time_elected                    float64\n",
       "count_victories                         int64\n",
       "unemployement_rate                    float64\n",
       "is_presidential_year                  float64\n",
       "president_can_be_re_elected           float64\n",
       "president_party                        object\n",
       "president_overall_avg_job_approval    float64\n",
       "last_D_house_seats                    float64\n",
       "last_R_house_seats                    float64\n",
       "last_house_majority                    object\n",
       "fundraising                           float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check for datatypes\n",
    "display(house_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>is_incumbent</th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>percent</th>\n",
       "      <th>state</th>\n",
       "      <th>votes</th>\n",
       "      <th>won</th>\n",
       "      <th>year</th>\n",
       "      <th>first_time_elected</th>\n",
       "      <th>count_victories</th>\n",
       "      <th>unemployement_rate</th>\n",
       "      <th>is_presidential_year</th>\n",
       "      <th>president_can_be_re_elected</th>\n",
       "      <th>president_party</th>\n",
       "      <th>president_overall_avg_job_approval</th>\n",
       "      <th>last_D_house_seats</th>\n",
       "      <th>last_R_house_seats</th>\n",
       "      <th>last_house_majority</th>\n",
       "      <th>fundraising</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>District 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>42.1</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>4281.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>42.8</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>5202.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1826</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>District 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>52.2</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1828</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>John Law</td>\n",
       "      <td>D</td>\n",
       "      <td>49.1</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>10868.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1830</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>District 1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ratliff Boon</td>\n",
       "      <td>D</td>\n",
       "      <td>50.9</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>11280.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1830</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     district  is_incumbent          name party  percent    state    votes  \\\n",
       "0  District 1           0.0  Ratliff Boon     D     42.1  Indiana   4281.0   \n",
       "1  District 1           1.0  Ratliff Boon     D     42.8  Indiana   5202.0   \n",
       "2  District 1           1.0  Ratliff Boon     D     52.2  Indiana   7272.0   \n",
       "3  District 1           0.0      John Law     D     49.1  Indiana  10868.0   \n",
       "4  District 1           1.0  Ratliff Boon     D     50.9  Indiana  11280.0   \n",
       "\n",
       "   won  year  first_time_elected  count_victories  unemployement_rate  \\\n",
       "0    1  1824              1824.0                0                 NaN   \n",
       "1    1  1826              1824.0                1                 NaN   \n",
       "2    1  1828              1824.0                2                 NaN   \n",
       "3    0  1830              1860.0                0                 NaN   \n",
       "4    1  1830              1824.0                3                 NaN   \n",
       "\n",
       "   is_presidential_year  president_can_be_re_elected president_party  \\\n",
       "0                   NaN                          NaN             NaN   \n",
       "1                   NaN                          NaN             NaN   \n",
       "2                   NaN                          NaN             NaN   \n",
       "3                   NaN                          NaN             NaN   \n",
       "4                   NaN                          NaN             NaN   \n",
       "\n",
       "   president_overall_avg_job_approval  last_D_house_seats  last_R_house_seats  \\\n",
       "0                                 NaN                 NaN                 NaN   \n",
       "1                                 NaN                 NaN                 NaN   \n",
       "2                                 NaN                 NaN                 NaN   \n",
       "3                                 NaN                 NaN                 NaN   \n",
       "4                                 NaN                 NaN                 NaN   \n",
       "\n",
       "  last_house_majority  fundraising  \n",
       "0                 NaN          NaN  \n",
       "1                 NaN          NaN  \n",
       "2                 NaN          NaN  \n",
       "3                 NaN          NaN  \n",
       "4                 NaN          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(house_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "district                                 0\n",
       "is_incumbent                           112\n",
       "name                                     0\n",
       "party                                    0\n",
       "percent                                 15\n",
       "state                                    0\n",
       "votes                                   67\n",
       "won                                      0\n",
       "year                                     0\n",
       "first_time_elected                    4445\n",
       "count_victories                          0\n",
       "unemployement_rate                     979\n",
       "is_presidential_year                   102\n",
       "president_can_be_re_elected            102\n",
       "president_party                        102\n",
       "president_overall_avg_job_approval    1060\n",
       "last_D_house_seats                     102\n",
       "last_R_house_seats                     102\n",
       "last_house_majority                    102\n",
       "fundraising                           7172\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get columns with NaN data\n",
    "house_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data normalisation\n",
    "def normalise_df(df, mins, maxs):\n",
    "    df = (df - mins)/(maxs - mins)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nan_model(data):\n",
    "    #model based imputation for columns fundraising and president_overall_avg_job_approval\n",
    "    #data: dataframe which is cleaned of NaNs but for the 2 mentioned variables\n",
    "    \n",
    "    #These are the 2 columns which will be imputed\n",
    "    missing_cols = ['fundraising', 'president_overall_avg_job_approval']\n",
    "        \n",
    "    data_origin = data.copy()\n",
    "    target_col = ['party'] #response variable\n",
    "    \n",
    "    #category variables will be dropped\n",
    "    del_columns = ['district','president_party','last_house_majority', 'name', 'state']\n",
    "    data = data.drop(columns = del_columns)\n",
    "    \n",
    "    #model can not deal with NaN values so we change them to the number 1 which didn't occur in the orignal dataset\n",
    "    #for those columns in missing_cols\n",
    "    data = data[missing_cols].fillna(1)\n",
    "\n",
    "    # dataset without any missing values; not normalised\n",
    "    clean_data = data[~((data[missing_cols[0]]==1) | \n",
    "                      (data[missing_cols[1]]==1))]\n",
    "    \n",
    "    # dataset with missing values that need to be imputed; not normalised\n",
    "    unclean_data = data[((data[missing_cols[0]]==1) | \n",
    "                      (data[missing_cols[1]]==1))]\n",
    "    \n",
    "    unclean_df = unclean_data.copy() # making fresh copy of unclean dataset\n",
    "    train_data = data.copy() #start with original dataset\n",
    "        \n",
    "    # running for 20 iterations for robustness\n",
    "    for it in range(20):\n",
    "        # finding missing values to be imputed using multiple linear regression model\n",
    "        for col in missing_cols:\n",
    "            sub_train = train_data\n",
    "            sub_test = unclean_data[unclean_data[col] == 1] # subset of unclean data with missing values in given column\n",
    "            \n",
    "            #split the data\n",
    "            sub_xtrain, sub_ytrain = sub_train[sub_train.columns.difference([col]+target_col)], sub_train[col]\n",
    "            sub_xtest, sub_ytest = sub_test[sub_test.columns.difference([col]+target_col)], sub_test[col] # sub_ytest is ones\n",
    "\n",
    "            # normalising the train and test predictors\n",
    "            sub_mins, sub_maxs = sub_xtrain.min(), sub_xtrain.max()\n",
    "            sub_xtrain = normalise_df(sub_xtrain, sub_mins, sub_maxs)\n",
    "            sub_xtest = normalise_df(sub_xtest, sub_mins, sub_maxs)    \n",
    "\n",
    "            #Imputation with linear regression\n",
    "            linreg = LinearRegression(fit_intercept=True)\n",
    "            linreg.fit(sub_xtrain, sub_ytrain)\n",
    "            sub_ytest_hat = linreg.predict(sub_xtest)\n",
    "\n",
    "            # impute values in the unclean dataframe\n",
    "            unclean_df[col].replace([1]*len(sub_ytest_hat), sub_ytest_hat, inplace=True)  \n",
    "\n",
    "            # re-construct the train dataset by combining clean data with newly imputed values\n",
    "            train_data = unclean_df.append(clean_data)\n",
    "            \n",
    "    #data = pd.concat([train_data, pd.DataFrame(data_origin,columns=data_origin.columns.difference(train_data))],sort=False, axis=1)\n",
    "    \n",
    "    #clean all NaN beside columns in missing_cols\n",
    "    #data = clean_nan_mean(data,i_type='model')\n",
    "    return  train_data[missing_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of NaNs\n",
    "def clean_nan(data,i_type='mean'):\n",
    "    #cleans NaNs\n",
    "    #data: dataframe\n",
    "    #i_type: if mean -> mean imputation only\n",
    "    #           if model -> model imputation for undraising and president_overall_avg_job_approval\n",
    "    \n",
    "    #delete duplicates\n",
    "    data = data.drop_duplicates(['year', 'state', 'district', 'name'])\n",
    "    \n",
    "    #needed just in case if not all NaNs are imputed with aggregated mean for fundraising below\n",
    "    mean_fund = data.fundraising.mean()\n",
    "    \n",
    "    #groups needed for imputation\n",
    "    gr_dist = data.groupby(['state', 'district'])\n",
    "    gr_year = data.groupby(['state', 'district','year'])\n",
    "    \n",
    "    #imputation of values\n",
    "    if i_type == 'mean':\n",
    "        data['president_overall_avg_job_approval'].fillna(gr_dist['president_overall_avg_job_approval'].transform('mean'), inplace=True)\n",
    "        data['fundraising'].fillna(gr_dist['fundraising'].transform('mean'), inplace=True)\n",
    "        data['fundraising'].fillna(mean_fund, inplace=True) #necessary if in first fundraising imputation NaNs remain\n",
    "    else:\n",
    "        model_df = clean_nan_model(data)\n",
    "        data['fundraising'] = model_df.fundraising\n",
    "        data['president_overall_avg_job_approval']=model_df.president_overall_avg_job_approval\n",
    "    data['votes'].fillna(gr_dist['votes'].transform('mean'), inplace=True)\n",
    "    data['last_D_house_seats'].fillna(gr_dist['last_D_house_seats'].transform('mean'), inplace=True)\n",
    "    data['last_R_house_seats'].fillna(gr_dist['last_R_house_seats'].transform('mean'), inplace=True)\n",
    "    data['percent'].fillna(100 - gr_year['percent'].transform('sum'), inplace=True)\n",
    "    data['unemployement_rate'].fillna(gr_dist['unemployement_rate'].transform('mean'), inplace=True)\n",
    "    data['is_presidential_year'].fillna(0, inplace=True)\n",
    "    data['president_can_be_re_elected'].fillna(1, inplace=True)\n",
    "    data['president_party'].fillna(0, inplace=True)\n",
    "    s = gr_year['is_incumbent'].transform(\"sum\")\n",
    "    r=[]\n",
    "    for index, item in enumerate(s):\n",
    "        if s[item] > 0:\n",
    "            r.append(0)\n",
    "        else:\n",
    "            r.append(1)\n",
    "    r = pd.Series(r)\n",
    "    data['is_incumbent'].fillna(r, inplace=True)\n",
    "    data['last_house_majority'].fillna(gr_dist['last_house_majority'].transform(lambda x: x.value_counts().index[0]), inplace=True)\n",
    "    data.loc[data['first_time_elected'].isna() & (data['won']==1),'first_time_elected'] = data.year\n",
    "    data.loc[data['first_time_elected'].isna() & (data['won']==0),'first_time_elected'] = 0\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#clean orignal dataset nan_df with mean only\n",
    "house_df = pd.read_csv('data/ready_to_use_dataset.csv')\n",
    "house_df_mean = clean_nan(house_df,i_type='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "district                              0\n",
       "is_incumbent                          0\n",
       "name                                  0\n",
       "party                                 0\n",
       "percent                               0\n",
       "state                                 0\n",
       "votes                                 0\n",
       "won                                   0\n",
       "year                                  0\n",
       "first_time_elected                    0\n",
       "count_victories                       0\n",
       "unemployement_rate                    0\n",
       "is_presidential_year                  0\n",
       "president_can_be_re_elected           0\n",
       "president_party                       0\n",
       "president_overall_avg_job_approval    0\n",
       "last_D_house_seats                    0\n",
       "last_R_house_seats                    0\n",
       "last_house_majority                   0\n",
       "fundraising                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test if imputation worked well\n",
    "house_df_mean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#model based imputation\n",
    "house_df = pd.read_csv('data/ready_to_use_dataset.csv')\n",
    "house_df_model = clean_nan(house_df, i_type='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "district                              0\n",
       "is_incumbent                          0\n",
       "name                                  0\n",
       "party                                 0\n",
       "percent                               0\n",
       "state                                 0\n",
       "votes                                 0\n",
       "won                                   0\n",
       "year                                  0\n",
       "first_time_elected                    0\n",
       "count_victories                       0\n",
       "unemployement_rate                    0\n",
       "is_presidential_year                  0\n",
       "president_can_be_re_elected           0\n",
       "president_party                       0\n",
       "president_overall_avg_job_approval    0\n",
       "last_D_house_seats                    0\n",
       "last_R_house_seats                    0\n",
       "last_house_majority                   0\n",
       "fundraising                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test if model based imputation worked\n",
    "house_df_model.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model and mean imputed data to csv\n",
    "house_df_mean.to_csv('data/house_mean_imputation.csv', index=False)\n",
    "house_df_model.to_csv('data/house_model_imputation.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corr_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-091a469cc797>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorr_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorr_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'party'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'R'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corr_df' is not defined"
     ]
    }
   ],
   "source": [
    "corr_df[corr_df['party'] == 'R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get correlations between variables  when Democrats or Republicans win\n",
    "def corr_heat(dataframe,party='D'):\n",
    "    f, ax = plt.subplots(figsize=(8, 6))\n",
    "    corr = dataframe[dataframe['party'] == party].drop('party', axis=1).corr()\n",
    "    sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "                square=True, ax=ax)\n",
    "    ax.set_title('Correlations when party {} won'.format(party))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display correlations\n",
    "corr_heat(house_df_mean[house_df_mean['year']!=2018], party='D')\n",
    "corr_heat(house_df_mean[house_df_mean['year']!=2018], party='R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are the categorical variables\n",
    "cat_cols=['president_party','state','district','last_house_majority','name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot-coding is necessary because of category variables\n",
    "#because it is no ordinary data we cannot do label encoding. So we do one-hot-encoding\n",
    "def one_hot_coding(data,cat_cols,y_year=2018):\n",
    "    #returns x and y variables for test and train\n",
    "    #data: dataframe\n",
    "    #cat_cols: enter array with category columns\n",
    "    #y_year: enter year for test data\n",
    "    \n",
    "    #create dummy features\n",
    "    data = pd.get_dummies(data, columns=cat_cols)\n",
    "    #create data sets for test and training\n",
    "    sel_train, sel_test=data[data['year']!=y_year], data[data['year']==y_year]\n",
    "    \n",
    "    #split for x and y\n",
    "    x_train, y_train=sel_train.drop('party', axis=1), sel_train['party']\n",
    "    x_test, y_test=sel_test.drop('party', axis=1), sel_test['party']\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Selection - categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi Square Test\n",
    "def chi2_test(x_col,y_col):\n",
    "    x = x_col.astype(str)\n",
    "    y= y_col.astype(str)\n",
    "\n",
    "    obs_val = pd.crosstab(y,x)\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(obs_val.values)\n",
    "    \n",
    "    return chi2, p, dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chi2_result(data,y_col='party',cat_cols=cat_cols,alpha=0.05):\n",
    "    for i in range(len(cat_cols)):\n",
    "        chi2, p, dof = chi2_test(data[cat_cols[i]],data[y_col])\n",
    "        if p>alpha:\n",
    "            print('Important for the prediction model: {} (p-value: {:+.3f}, chi2: {:+.1f})'.format(cat_cols[i],p,chi2))\n",
    "        else:\n",
    "            print('\\033[1mNOT\\033[0m important for the prediction model: \\033[1m{}\\033[0m (p-value: {:+.3f}, chi2: {:+.1f})'.format(cat_cols[i],p,chi2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the result of Chi Square Test\n",
    "print_chi2_result(house_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation: \n",
    "- Column \"name\" is not useful in the models\n",
    "- But because of feature engineering during the modeling it will be needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Selection - Random Forest with one-hot-coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy of original dataset\n",
    "forest_df = house_df.copy()\n",
    "\n",
    "#Exclude column name because of low p-value - see chapter \"Variable Selection - categorical variables\"\n",
    "forest_df = forest_df.drop(columns = 'name')\n",
    "\n",
    "#categorical columns for Random Forest model\n",
    "forest_cat=['president_party','state','district','last_house_majority']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_sel_RF(forest_df,forest_cat=forest_cat,y_year=2018, threshold=0.003):\n",
    "    #returns 1) sorted list of most important features\n",
    "    #        2) Accuracy of model with all features and with selected features\n",
    "    #thresold: minimum feature importance\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = one_hot_coding(forest_df,forest_cat,y_year)\n",
    "    \n",
    "    # Create a random forest classifier. number of trees set to 100\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    \n",
    "    # Train the classifier\n",
    "    clf.fit(x_train, y_train)\n",
    "    feat_labels = x_train.columns\n",
    "    feat_imp = []\n",
    "    \n",
    "    # name and gini importance of each feature\n",
    "    for feature in zip(clf.feature_importances_,feat_labels):\n",
    "        feat_imp.append(feature)\n",
    "    feat_imp.sort(reverse=True)\n",
    "    \n",
    "    #sorted list with most important features\n",
    "    feat_imp = list(filter(lambda x: x[0] > threshold, feat_imp))\n",
    "    \n",
    "    # Create a selector object that will use the random forest classifier to identify\n",
    "    # features that have an importance of more than 0.003\n",
    "    sfm = SelectFromModel(clf, threshold=threshold)\n",
    "\n",
    "    # Train the selector\n",
    "    sfm.fit(x_train, y_train)\n",
    "    \n",
    "    # Transform the data to create a new dataset containing only the most important features\n",
    "    # Note: We have to apply the transform to both the training X and test X data.\n",
    "    X_important_train = sfm.transform(x_train)\n",
    "    X_important_test = sfm.transform(x_test)\n",
    "    \n",
    "    # Create a new random forest classifier for the most important features\n",
    "    clf_important = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "\n",
    "    # Train the new classifier on the new dataset containing the most important features\n",
    "    clf_important.fit(X_important_train, y_train)\n",
    "    \n",
    "    # Accuracy of model with all features\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print('Accuracy of model with all features: {:+.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "    # Accuracy of model with most important features\n",
    "    y_important_pred = clf_important.predict(X_important_test)\n",
    "    print('Accuracy of model with most important features: {:+.3f}'.format(accuracy_score(y_test, y_important_pred)))\n",
    "    \n",
    "    return feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_sel_RF(forest_df,forest_cat=forest_cat,y_year=2018, threshold=0.007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#further modeling for baseline with mean imputed data\n",
    "house_df = house_df_mean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(house_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that we always have one (and only one) winner per district\n",
    "house_df_grouped=house_df.groupby(['year', 'state', 'district'])['won'].sum().reset_index(drop=False)\n",
    "house_df_grouped[house_df_grouped['won']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show that we have to remove first_time_elected if it's in the future, compared to current observation\n",
    "house_df[(house_df['year']-house_df['first_time_elected']<=0)&(house_df['name']=='John Law')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fundraising\n",
    "def fundraisingVsPresidentialYear(df):\n",
    "    df_plt=df.dropna(subset=['fundraising', 'is_presidential_year']).copy()\n",
    "    #df_plt.loc[df_plt['fundraising']<=0, 'fundraising']=1 #remove zero values\n",
    "    df_plt=df_plt[df_plt['fundraising']>0]\n",
    "    df_plt['fundraising']=np.log10(df_plt['fundraising']) #take the log10\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    fig.suptitle('Fund raised in presidential or non presidential elections', fontsize=24, y=0.95)\n",
    "    #print(i, year)\n",
    "    sns.distplot(df_plt[df_plt['is_presidential_year']==1]['fundraising'], ax=ax, label='presidential')\n",
    "    sns.distplot(df_plt[df_plt['is_presidential_year']==0]['fundraising'], ax=ax, label='mid-term')\n",
    "    #set x label\n",
    "    ax.set_xlabel('Funds raised in log10($)')\n",
    "    #set y label\n",
    "    ax.set_ylabel('Density')\n",
    "    #set title\n",
    "    #ax[i].set_title('year {}'.format(year))\n",
    "    #set legend\n",
    "    ax.legend()\n",
    "fundraisingVsPresidentialYear(house_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df_district_count=house_df.loc[house_df['year']==2017]\n",
    "house_df_district_count.groupby(['state', 'district'])['name'].first()\n",
    "\n",
    "house_df[(house_df['state']=='California')&(house_df['district']=='District 34')&(house_df['year']==2017)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many observations we have for each district. \n",
    "house_df_grouped=house_df[house_df['year']!=2018].groupby(['state', 'district'])['party'].count()\n",
    "house_df_grouped.reset_index(drop=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wonParty=house_df[house_df['won']>0.5][['year','state', 'district', 'party']]\n",
    "#wonParty=wonParty.rename(index=str, columns={\"party\": \"wonParty\"})\n",
    "#house_df2=house_df.join(wonParty.set_index(['year', 'state', 'district']), on=['year', 'state', 'district'])\n",
    "house_df2=house_df.copy()\n",
    "house_df2['R_vs_D_Seats']=house_df2['last_R_house_seats']/(house_df2['last_R_house_seats']+house_df2['last_D_house_seats']) #1=100% R, 0=100% D\n",
    "house_df2['WinLoseParty']=house_df2['party'].astype(str)+house_df2['won'].replace([0, 1], ['Loser', 'Winner'])\n",
    "house_df2['won']=house_df2['won'].replace([0, 1], ['Loser', 'Winner'])\n",
    "house_df2['LogFundraising']=house_df2['fundraising'].copy()\n",
    "house_df2.loc[house_df2['LogFundraising']<=0, 'LogFundraising']=np.NaN\n",
    "house_df2['LogFundraising']=np.log10(house_df2['LogFundraising']) #take the log10\n",
    "#df['Year'].astype(str) + df['quarter']\n",
    "house_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palettes for parties or other\n",
    "Parties_palette=[(0.12156862745098039, 0.4666666666666667, 0.7058823529411765),\n",
    "             (0.8392156862745098, 0.15294117647058825, 0.1568627450980392),\n",
    "             (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "             (1.0, 0.4980392156862745, 0.054901960784313725),\n",
    "             (0.5803921568627451, 0.403921568627451, 0.7411764705882353),\n",
    "             (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),\n",
    "             (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),\n",
    "             (0.4980392156862745, 0.4980392156862745, 0.4980392156862745),\n",
    "             (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),\n",
    "             (0.09019607843137255, 0.7450980392156863, 0.8117647058823529)]\n",
    "WinLosePalette=[(0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "             (1.0, 0.4980392156862745, 0.054901960784313725),\n",
    "             (0.5803921568627451, 0.403921568627451, 0.7411764705882353),\n",
    "             (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),\n",
    "             (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),\n",
    "             (0.4980392156862745, 0.4980392156862745, 0.4980392156862745),\n",
    "             (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),\n",
    "             (0.09019607843137255, 0.7450980392156863, 0.8117647058823529)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(house_df2[[\n",
    " 'party',\n",
    " 'count_victories',\n",
    " 'unemployement_rate',\n",
    " 'president_party',\n",
    " 'president_overall_avg_job_approval',\n",
    " 'last_house_majority',\n",
    " 'LogFundraising',\n",
    " #'WinLoseParty',\n",
    " #'wonParty',\n",
    " 'R_vs_D_Seats',\n",
    " 'won']], hue=\"won\",  palette=WinLosePalette, plot_kws=dict(s=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(house_df2[house_df2['won']=='Winner'][[\n",
    " 'party',\n",
    " 'count_victories',\n",
    " 'unemployement_rate',\n",
    " 'president_party',\n",
    " 'president_overall_avg_job_approval',\n",
    " 'last_house_majority',\n",
    " 'LogFundraising',\n",
    " #'WinLoseParty',\n",
    " #'wonParty',\n",
    " 'R_vs_D_Seats',\n",
    " 'won']], hue=\"party\",  palette=Parties_palette, plot_kws=dict(s=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house_df2=house_df.set_index(['year', 'state', 'district', 'name']).dropna().copy()\n",
    "house_df2=house_df.dropna().copy()\n",
    "house_df2_districts=house_df2[['state','district']]\n",
    "house_df2=house_df2.drop('state', axis=1).drop('district', axis=1).drop('name', axis=1)\n",
    "house_df2['party']=house_df2['party'].replace(['D', 'R'], [0, 1])\n",
    "house_df2['president_party']=house_df2['president_party'].replace(['D', 'R'], [0, 1])\n",
    "house_df2['last_house_majority']=house_df2['last_house_majority'].replace(['D', 'R'], [0, 1])\n",
    "\n",
    "data_train, data_test=house_df2[house_df2['year']!=2018], house_df2[house_df2['year']==2018]\n",
    "\n",
    "x_train, y_train=data_train.drop('won', axis=1), data_train['won']\n",
    "\n",
    "x_test, y_test=data_test.drop('won', axis=1), data_test['won']\n",
    "baselineLogRegr=LogisticRegressionCV(cv=5, penalty='l2').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy is defined as (TP+TN)/n\n",
    "def printAccuracy(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    print('Training Set Accuracy: \\t{:.2%}'.format(np.sum(y_train == y_pred_train) / len(y_train)))\n",
    "    print('Test Set Accuracy: \\t{:.2%}'.format(np.sum(y_test == y_pred_test) / len(y_test)))\n",
    "\n",
    "y_pred_train=baselineLogRegr.predict(x_train)\n",
    "y_pred_test=baselineLogRegr.predict(x_test)\n",
    "printAccuracy(y_train, y_pred_train, y_test, y_pred_test)\n",
    "print('Amount of districts in the predictions: {:.1%} of the total'.format(len(x_test.join(house_df2_districts).groupby(['state', 'district']).count())/435))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline model \n",
    "def winnerFilter(df):\n",
    "    return df[df['won']==1][['state', 'district','party']]\n",
    "    \n",
    "#def baselineTrain(df):\n",
    "#    df_grouped=df[df['won']==1 ].groupby(['state', 'district', 'party'])['won'].count().reset_index(drop=False)\n",
    "#    df_grouped=df_grouped.groupby(['state', 'district']).agg({'won':'max',      \n",
    "#                                         'party': 'first'})\n",
    "#    return df_grouped.drop('won', axis=1).reset_index(drop=False)\n",
    "def baselineTrain(df):\n",
    "    df_grouped=df[(df['won']==1)].groupby(['state', 'district'])['party'].sum().reset_index(drop=False)\n",
    "    df_grouped['R_occurence']=df_grouped['party'].str.count('R')/df_grouped['party'].str.len()\n",
    "    df_grouped['party']=(df_grouped['R_occurence']>0.5).astype(int).replace([0, 1], ['D', 'R'])\n",
    "    df_grouped['proba']=(1-df_grouped['party']-df_grouped['R_occurence']).abs()\n",
    "    return df_grouped[['state', 'district','party', 'proba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=baselineTrain(house_df[house_df['year']!=2018]) #train simple average model, remove 2018 results\n",
    "y=winnerFilter(house_df[house_df['year']==2018]) #extract winner party for each district in 2018\n",
    "\n",
    "results=[]\n",
    "for state in y['state'].unique():\n",
    "    for district in y[y['state']==state]['district']:\n",
    "        actual=y.loc[(y['state']==state)&(y['district']==district), 'party']\n",
    "        pred=y_pred.loc[(y_pred['state']==state)&(y_pred['district']==district), 'party']\n",
    "        #print('pred:{}, \\nactual:{}, \\npred.all():{}, \\nactual.all():{}\\n result:{}\\n'.format(pred, actual, pred.all(), actual.all(), actual.all()==pred.all()))\n",
    "        results.append(actual.all()==pred.all())\n",
    "print('Test Set Accuracy: \\t{:.2%}'.format(sum(results)/len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deductPartisanship(trainData, HistYears=50):\n",
    "    #compute the prevalence of one party win against the other\n",
    "    house_df_all_districts=trainData[(trainData['won']==1) & (trainData['year']>=(2018-HistYears)) & (trainData['year']!=2018)].groupby(['state', 'district'])['party'].sum().reset_index(drop=False)\n",
    "    house_df_all_districts['R_occurence']=house_df_all_districts['party'].str.count('R')/house_df_all_districts['party'].str.len()\n",
    "\n",
    "    avgHistData=house_df_all_districts['party'].str.len().mean() #Average amount of historical data per district\n",
    "    histDataThreshold=avgHistData/2\n",
    "\n",
    "    print('In average, in the last {} years, we have data from the last {:.1f} elections in each district.\\nSome districts are \"new\" as they exist only after a redistribution for a new congress. \\nWe evaluate the partisanships of districts which exist at least since the last {:.1f} elections'.format(HistYears, avgHistData, histDataThreshold))\n",
    "\n",
    "    #3=traditionally Republican district\n",
    "    #2=traditionally Democratic district\n",
    "    #1=swing district\n",
    "    #0=Recent district (Not enough historical data)\n",
    "    house_df_all_districts['partisanship']=(house_df_all_districts['party'].str.len()>=histDataThreshold)*(\n",
    "                      (house_df_all_districts['R_occurence']>(2/3))*3\n",
    "                    + (house_df_all_districts['R_occurence']<=(1/3))*2\n",
    "                    + ((house_df_all_districts['R_occurence']>(1/3))\n",
    "                      &(house_df_all_districts['R_occurence']<=(2/3)))*1\n",
    "                    )\n",
    "    return house_df_all_districts[['state', 'district', 'partisanship']]\n",
    "\n",
    "def assignPartisanship(train_df, test_df):\n",
    "    return test_df.join(deductPartisanship(train_df).set_index(['state', 'district']), on=['state', 'district'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, df):\n",
    "    out_df=assignPartisanship(train_df, df).copy()\n",
    "    out_df['first_time_elected']=out_df['year']-out_df['first_time_elected']\n",
    "    out_df.loc[out_df['first_time_elected']<0, 'first_time_elected']=np.NaN\n",
    "    out_df['Log10fundraising']=out_df['fundraising']\n",
    "    out_df.loc[out_df['Log10fundraising']<=0, 'Log10fundraising']=np.NaN\n",
    "    out_df['Log10fundraising']=np.log10(out_df['fundraising']) #take the log10\n",
    "    return out_df[['is_incumbent',\n",
    "                   'party', \n",
    "                   'first_time_elected', \n",
    "                   'count_victories', \n",
    "                   'unemployement_rate', \n",
    "                   'is_presidential_year',\n",
    "                   'president_can_be_re_elected',\n",
    "                   'president_party',\n",
    "                   'president_overall_avg_job_approval',\n",
    "                   'last_D_house_seats',\n",
    "                   'last_R_house_seats',\n",
    "                   'last_house_majority',\n",
    "                   'fundraising',\n",
    "                   'won'\n",
    "                  ]]\n",
    "\n",
    "msk=house_df['year']!=2018\n",
    "data_train=preprocess(house_df[msk], house_df[msk])\n",
    "data_test=preprocess(house_df[msk], house_df[~msk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with all correlations for Republicans win\n",
    "drop = ['won','votes', 'percent', 'year', 'first_time_elected', 'is_presidential_year', 'last_D_house_seats', 'last_R_house_seats','president_can_be_re_elected']\n",
    "corr_df = house_df2.copy()\n",
    "corr_df = corr_df.drop(drop, axis=1)\n",
    "corr_df[corr_df['party'] == 1].drop('party', axis=1).corr().style.format(\"{:.2}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with all correlations for Democrats win\n",
    "corr_df[corr_df['party'] == 0].drop('party',axis=1).corr().style.format(\"{:.2}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_all = ['last_house_majority','is_incumbent', 'count_victories','unemployement_rate', 'president_overall_avg_job_approval','fundraising']\n",
    "\n",
    "# comparison of variables with boxplots\n",
    "def expl_boxplots(dataframe,variables):\n",
    "    house_df2_D = dataframe[dataframe['party'] == 0]\n",
    "    house_df2_R = dataframe[dataframe['party'] == 1]\n",
    "    fig = plt.figure(figsize=(10,6))\n",
    "    for i in range(len(var_all)):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        a = pd.DataFrame({ 'group' : np.repeat('Democrat',house_df2_D.shape[0]), 'value': house_df2_D[var_all[i]] })\n",
    "        b = pd.DataFrame({ 'group' : np.repeat('Republican',house_df2_R.shape[0]), 'value': house_df2_R[var_all[i]] })\n",
    "        plt.title(var_all[i])\n",
    "        df=a.append(b)\n",
    "        # Usual boxplot\n",
    "        sns.boxplot(x='group', y='value', data=df)\n",
    "    fig\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_boxplots(house_df2,var_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
