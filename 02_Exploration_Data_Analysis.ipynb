{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-666c0970bcc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[1;31m# avoid flakes unused variable error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m from .validation import (as_float_array,\n\u001b[0m\u001b[0;32m     12\u001b[0m                          \u001b[0massert_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                          \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMemorizedResult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPrintTime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_memory_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopen_py_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdisk\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmkdirp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrm_subdirs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemstr_to_bytes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPY3_OR_LATER\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mnumpy_pickle_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mZNDArrayWrapper\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_basestring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPY3_OR_LATER\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbackports\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_memmap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_cache_bytecode\u001b[1;34m(self, source_path, bytecode_path, data)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, path, data, _mode)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_write_atomic\u001b[1;34m(path, data, mode)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the data set and take a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df = pd.read_csv('data/ready_to_use_dataset.csv')\n",
    "house_df = house_df.drop_duplicates(['year', 'state', 'district', 'name'])\n",
    "display(house_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(house_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(house_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(house_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(house_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has 9974 observations and 20 predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk=(house_df['year']==1972) & (house_df['state']=='Minnesota') & (house_df['district']=='District 6')\n",
    "house_df[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that we always have one (and only one) winner per district\n",
    "house_df_grouped=house_df.groupby(['year', 'state', 'district'])['won'].sum().reset_index(drop=False)\n",
    "house_df_grouped[house_df_grouped['won']!=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show that we have to remove first_time_elected if it's in the future, compared to current observation\n",
    "house_df[(house_df['year']-house_df['first_time_elected']<=0)&(house_df['name']=='John Law')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fundraising\n",
    "def fundraisingVsPresidentialYear(df):\n",
    "    df_plt=df.dropna(subset=['fundraising', 'is_presidential_year']).copy()\n",
    "    #df_plt.loc[df_plt['fundraising']<=0, 'fundraising']=1 #remove zero values\n",
    "    df_plt=df_plt[df_plt['fundraising']>0]\n",
    "    df_plt['fundraising']=np.log10(df_plt['fundraising']) #take the log10\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "    fig.suptitle('Fund raised in presidential or non presidential elections', fontsize=24, y=0.95)\n",
    "    #print(i, year)\n",
    "    sns.distplot(df_plt[df_plt['is_presidential_year']==1]['fundraising'], ax=ax, label='presidential')\n",
    "    sns.distplot(df_plt[df_plt['is_presidential_year']==0]['fundraising'], ax=ax, label='mid-term')\n",
    "    #set x label\n",
    "    ax.set_xlabel('Funds raised in log10($)')\n",
    "    #set y label\n",
    "    ax.set_ylabel('Density')\n",
    "    #set title\n",
    "    #ax[i].set_title('year {}'.format(year))\n",
    "    #set legend\n",
    "    ax.legend()\n",
    "fundraisingVsPresidentialYear(house_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_df_district_count=house_df.loc[house_df['year']==2017]\n",
    "house_df_district_count.groupby(['state', 'district'])['name'].first()\n",
    "\n",
    "house_df[(house_df['state']=='California')&(house_df['district']=='District 34')&(house_df['year']==2017)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many observations we have for each district. \n",
    "house_df_grouped=house_df[house_df['year']!=2018].groupby(['state', 'district'])['party'].count()\n",
    "house_df_grouped.reset_index(drop=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wonParty=house_df[house_df['won']>0.5][['year','state', 'district', 'party']]\n",
    "#wonParty=wonParty.rename(index=str, columns={\"party\": \"wonParty\"})\n",
    "#house_df2=house_df.join(wonParty.set_index(['year', 'state', 'district']), on=['year', 'state', 'district'])\n",
    "house_df2=house_df.copy()\n",
    "house_df2['R_vs_D_Seats']=house_df2['last_R_house_seats']/(house_df2['last_R_house_seats']+house_df2['last_D_house_seats']) #1=100% R, 0=100% D\n",
    "house_df2['WinLoseParty']=house_df2['party'].astype(str)+house_df2['won'].replace([0, 1], ['Loser', 'Winner'])\n",
    "house_df2['won']=house_df2['won'].replace([0, 1], ['Loser', 'Winner'])\n",
    "house_df2['LogFundraising']=house_df2['fundraising'].copy()\n",
    "house_df2.loc[house_df2['LogFundraising']<=0, 'LogFundraising']=np.NaN\n",
    "house_df2['LogFundraising']=np.log10(house_df2['LogFundraising']) #take the log10\n",
    "#df['Year'].astype(str) + df['quarter']\n",
    "house_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#palettes for parties or other\n",
    "Parties_palette=[(0.12156862745098039, 0.4666666666666667, 0.7058823529411765),\n",
    "             (0.8392156862745098, 0.15294117647058825, 0.1568627450980392),\n",
    "             (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "             (1.0, 0.4980392156862745, 0.054901960784313725),\n",
    "             (0.5803921568627451, 0.403921568627451, 0.7411764705882353),\n",
    "             (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),\n",
    "             (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),\n",
    "             (0.4980392156862745, 0.4980392156862745, 0.4980392156862745),\n",
    "             (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),\n",
    "             (0.09019607843137255, 0.7450980392156863, 0.8117647058823529)]\n",
    "WinLosePalette=[(0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "             (1.0, 0.4980392156862745, 0.054901960784313725),\n",
    "             (0.5803921568627451, 0.403921568627451, 0.7411764705882353),\n",
    "             (0.5490196078431373, 0.33725490196078434, 0.29411764705882354),\n",
    "             (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),\n",
    "             (0.4980392156862745, 0.4980392156862745, 0.4980392156862745),\n",
    "             (0.7372549019607844, 0.7411764705882353, 0.13333333333333333),\n",
    "             (0.09019607843137255, 0.7450980392156863, 0.8117647058823529)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(house_df2[[\n",
    " 'party',\n",
    " 'count_victories',\n",
    " 'unemployement_rate',\n",
    " 'president_party',\n",
    " 'president_overall_avg_job_approval',\n",
    " 'last_house_majority',\n",
    " 'LogFundraising',\n",
    " #'WinLoseParty',\n",
    " #'wonParty',\n",
    " 'R_vs_D_Seats',\n",
    " 'won']], hue=\"won\",  palette=WinLosePalette, plot_kws=dict(s=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(house_df2[house_df2['won']=='Winner'][[\n",
    " 'party',\n",
    " 'count_victories',\n",
    " 'unemployement_rate',\n",
    " 'president_party',\n",
    " 'president_overall_avg_job_approval',\n",
    " 'last_house_majority',\n",
    " 'LogFundraising',\n",
    " #'WinLoseParty',\n",
    " #'wonParty',\n",
    " 'R_vs_D_Seats',\n",
    " 'won']], hue=\"party\",  palette=Parties_palette, plot_kws=dict(s=25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house_df2=house_df.set_index(['year', 'state', 'district', 'name']).dropna().copy()\n",
    "house_df2=house_df.dropna().copy()\n",
    "house_df2_districts=house_df2[['state','district']]\n",
    "house_df2=house_df2.drop('state', axis=1).drop('district', axis=1).drop('name', axis=1)\n",
    "house_df2['party']=house_df2['party'].replace(['D', 'R'], [0, 1])\n",
    "house_df2['president_party']=house_df2['president_party'].replace(['D', 'R'], [0, 1])\n",
    "house_df2['last_house_majority']=house_df2['last_house_majority'].replace(['D', 'R'], [0, 1])\n",
    "\n",
    "data_train, data_test=house_df2[house_df2['year']!=2018], house_df2[house_df2['year']==2018]\n",
    "\n",
    "x_train, y_train=data_train.drop('won', axis=1), data_train['won']\n",
    "\n",
    "x_test, y_test=data_test.drop('won', axis=1), data_test['won']\n",
    "baselineLogRegr=LogisticRegressionCV(cv=5, penalty='l2').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy is defined as (TP+TN)/n\n",
    "def printAccuracy(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    print('Training Set Accuracy: \\t{:.2%}'.format(np.sum(y_train == y_pred_train) / len(y_train)))\n",
    "    print('Test Set Accuracy: \\t{:.2%}'.format(np.sum(y_test == y_pred_test) / len(y_test)))\n",
    "\n",
    "y_pred_train=baselineLogRegr.predict(x_train)\n",
    "y_pred_test=baselineLogRegr.predict(x_test)\n",
    "printAccuracy(y_train, y_pred_train, y_test, y_pred_test)\n",
    "print('Amount of districts in the predictions: {:.1%} of the total'.format(len(x_test.join(house_df2_districts).groupby(['state', 'district']).count())/435))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline model \n",
    "def winnerFilter(df):\n",
    "    return df[df['won']==1][['state', 'district','party']]\n",
    "    \n",
    "def baselineTrain(df):\n",
    "    df_grouped=df[df['won']==1 ].groupby(['state', 'district', 'party'])['won'].count().reset_index(drop=False)\n",
    "    df_grouped=df_grouped.groupby(['state', 'district']).agg({'won':'max',      \n",
    "                                         'party': 'first'})\n",
    "    return df_grouped.drop('won', axis=1).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=baselineTrain(house_df[house_df['year']!=2018]) #train simple average model, remove 2018 results\n",
    "y=winnerFilter(house_df[house_df['year']==2018]) #extract winner party for each district in 2018\n",
    "\n",
    "results=[]\n",
    "for state in y['state'].unique():\n",
    "    for district in y[y['state']==state]['district']:\n",
    "        actual=y.loc[(y['state']==state)&(y['district']==district), 'party']\n",
    "        pred=y_pred.loc[(y_pred['state']==state)&(y_pred['district']==district), 'party']\n",
    "        #print('pred:{}, \\nactual:{}, \\npred.all():{}, \\nactual.all():{}\\n result:{}\\n'.format(pred, actual, pred.all(), actual.all(), actual.all()==pred.all()))\n",
    "        results.append(actual.all()==pred.all())\n",
    "print('Test Set Accuracy: \\t{:.2%}'.format(sum(results)/len(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deductPartisanship(trainData, HistYears=50):\n",
    "    #compute the prevalence of one party win against the other\n",
    "    house_df_all_districts=trainData[(trainData['won']==1) & (trainData['year']>=(2018-HistYears)) & (trainData['year']!=2018)].groupby(['state', 'district'])['party'].sum().reset_index(drop=False)\n",
    "    house_df_all_districts['R_occurence']=house_df_all_districts['party'].str.count('R')/house_df_all_districts['party'].str.len()\n",
    "\n",
    "    avgHistData=house_df_all_districts['party'].str.len().mean() #Average amount of historical data per district\n",
    "    histDataThreshold=avgHistData/2\n",
    "\n",
    "    print('In average, in the last {} years, we have data from the last {:.1f} elections in each district.\\nSome districts are \"new\" as they exist only after a redistribution for a new congress. \\nWe evaluate the partisanships of districts which exist at least since the last {:.1f} elections'.format(HistYears, avgHistData, histDataThreshold))\n",
    "\n",
    "    #3=traditionally Republican district\n",
    "    #2=traditionally Democratic district\n",
    "    #1=swing district\n",
    "    #0=Recent district (Not enough historical data)\n",
    "    house_df_all_districts['partisanship']=(house_df_all_districts['party'].str.len()>=histDataThreshold)*(\n",
    "                      (house_df_all_districts['R_occurence']>(2/3))*3\n",
    "                    + (house_df_all_districts['R_occurence']<=(1/3))*2\n",
    "                    + ((house_df_all_districts['R_occurence']>(1/3))\n",
    "                      &(house_df_all_districts['R_occurence']<=(2/3)))*1\n",
    "                    )\n",
    "    return house_df_all_districts[['state', 'district', 'partisanship']]\n",
    "\n",
    "def assignPartisanship(train_df, test_df):\n",
    "    return test_df.join(deductPartisanship(train_df).set_index(['state', 'district']), on=['state', 'district'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, df):\n",
    "    out_df=assignPartisanship(train_df, df).copy()\n",
    "    out_df['first_time_elected']=out_df['year']-out_df['first_time_elected']\n",
    "    out_df.loc[out_df['first_time_elected']<0, 'first_time_elected']=np.NaN\n",
    "    out_df['Log10fundraising']=out_df['fundraising']\n",
    "    out_df.loc[out_df['Log10fundraising']<=0, 'Log10fundraising']=np.NaN\n",
    "    out_df['Log10fundraising']=np.log10(out_df['fundraising']) #take the log10\n",
    "    return out_df[['is_incumbent',\n",
    "                   'party', \n",
    "                   'first_time_elected', \n",
    "                   'count_victories', \n",
    "                   'unemployement_rate', \n",
    "                   'is_presidential_year',\n",
    "                   'president_can_be_re_elected',\n",
    "                   'president_party',\n",
    "                   'president_overall_avg_job_approval',\n",
    "                   'last_D_house_seats',\n",
    "                   'last_R_house_seats',\n",
    "                   'last_house_majority',\n",
    "                   'fundraising',\n",
    "                   'won'\n",
    "                  ]]\n",
    "\n",
    "msk=house_df['year']!=2018\n",
    "data_train=preprocess(house_df[msk], house_df[msk])\n",
    "data_test=preprocess(house_df[msk], house_df[~msk])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
