{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define some usefull functions we will use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_or_save_page(filename, url):\n",
    "    \"\"\"\n",
    "        Check if the file exist, if not get the page\n",
    "        from the url and store in on the disk\n",
    "        Returns the file content as a soup\n",
    "    \"\"\"\n",
    "    # Check if the page has been stored on disk\n",
    "    if Path(filename).is_file() is False:\n",
    "        #print('No page')\n",
    "        # Get the page\n",
    "        result = requests.get(url)\n",
    "        with open(filename,'w') as outfile:\n",
    "            outfile.write(result.text)\n",
    "        time.sleep(2)\n",
    "    #else:\n",
    "        #print('We got it')\n",
    "        \n",
    "    with open(filename) as my_file:\n",
    "        soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "        \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection - Web Scraping - Data Parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DatesinOffice</th>\n",
       "      <th>DaysInOffice</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>FirstTermAverage</th>\n",
       "      <th>JobApprovalHigh</th>\n",
       "      <th>JobApprovalLow</th>\n",
       "      <th>OverallAverage</th>\n",
       "      <th>Party</th>\n",
       "      <th>PresidentName</th>\n",
       "      <th>SecondTermAverage</th>\n",
       "      <th>StartDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-Present</td>\n",
       "      <td>658</td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>45.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>Rep.</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>-</td>\n",
       "      <td>2017-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-2017</td>\n",
       "      <td>2922</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>Dem.</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>47</td>\n",
       "      <td>2009-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-2009</td>\n",
       "      <td>2922</td>\n",
       "      <td>2009-01-20</td>\n",
       "      <td>62.2</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "      <td>49.4</td>\n",
       "      <td>Rep.</td>\n",
       "      <td>George W. Bush</td>\n",
       "      <td>36.5</td>\n",
       "      <td>2001-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993-2001</td>\n",
       "      <td>2922</td>\n",
       "      <td>2001-01-20</td>\n",
       "      <td>49.6</td>\n",
       "      <td>73</td>\n",
       "      <td>37</td>\n",
       "      <td>55.1</td>\n",
       "      <td>Dem.</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>60.6</td>\n",
       "      <td>1993-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1989-1993</td>\n",
       "      <td>1461</td>\n",
       "      <td>1993-01-20</td>\n",
       "      <td>60.9</td>\n",
       "      <td>89</td>\n",
       "      <td>29</td>\n",
       "      <td>60.9</td>\n",
       "      <td>Rep.</td>\n",
       "      <td>George H. W. Bush</td>\n",
       "      <td>-</td>\n",
       "      <td>1989-01-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DatesinOffice DaysInOffice     EndDate FirstTermAverage JobApprovalHigh  \\\n",
       "0  2017-Present          658                            -            45.0   \n",
       "1     2009-2017         2922  2017-01-20               48              67   \n",
       "2     2001-2009         2922  2009-01-20             62.2              90   \n",
       "3     1993-2001         2922  2001-01-20             49.6              73   \n",
       "4     1989-1993         1461  1993-01-20             60.9              89   \n",
       "\n",
       "  JobApprovalLow OverallAverage Party      PresidentName SecondTermAverage  \\\n",
       "0           35.0           39.5  Rep.    Donald J. Trump                 -   \n",
       "1             40             48  Dem.       Barack Obama                47   \n",
       "2             25           49.4  Rep.     George W. Bush              36.5   \n",
       "3             37           55.1  Dem.       Bill Clinton              60.6   \n",
       "4             29           60.9  Rep.  George H. W. Bush                 -   \n",
       "\n",
       "    StartDate  \n",
       "0  2017-01-20  \n",
       "1  2009-01-20  \n",
       "2  2001-01-20  \n",
       "3  1993-01-20  \n",
       "4  1989-01-20  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Declare global variables\n",
    "states = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming', 'District of Columbia']\n",
    "\n",
    "# National unemployement rate by month from 1948 to 2018\n",
    "# Source: https://data.bls.gov/pdq/SurveyOutputServlet\n",
    "national_unemployement_rate = pd.read_csv('data/national_unemployement_1948_2018.csv')\n",
    "\n",
    "# Get the presidental job approval\n",
    "# Source: https://www.gallup.com\n",
    "# https://news.gallup.com/interactives/185273/presidential-job-approval-center.aspx\n",
    "with open('data/all_presidential_job_approval_gallup.json') as f:\n",
    "    presidential_approval = json.load(f)\n",
    "presidential_approval = presidential_approval['AllPresidents']['HistoricalPresident']\n",
    "presidential_approval_df = pd.DataFrame.from_dict([x['PresidentData'] for x in presidential_approval])\n",
    "display(presidential_approval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1949</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1951</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1952</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n",
       "0  1948  3.4  3.8  4.0  3.9  3.5  3.6  3.6  3.9  3.8  3.7  3.8  4.0\n",
       "1  1949  4.3  4.7  5.0  5.3  6.1  6.2  6.7  6.8  6.6  7.9  6.4  6.6\n",
       "2  1950  6.5  6.4  6.3  5.8  5.5  5.4  5.0  4.5  4.4  4.2  4.2  4.3\n",
       "3  1951  3.7  3.4  3.4  3.1  3.0  3.2  3.1  3.1  3.3  3.5  3.5  3.1\n",
       "4  1952  3.2  3.1  2.9  2.9  3.0  3.0  3.2  3.4  3.1  3.0  2.8  2.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(national_unemployement_rate.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get once the necessary pages\n",
    "presidential_page = requests.get('https://en.wikipedia.org/wiki/United_States_presidential_election')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>president_elected</th>\n",
       "      <th>president_elected_party</th>\n",
       "      <th>can_be_re_elected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1824</td>\n",
       "      <td>John Quincy Adams</td>\n",
       "      <td>DR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1828</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1832</td>\n",
       "      <td>Andrew Jackson</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1836</td>\n",
       "      <td>Martin Van Buren</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1840</td>\n",
       "      <td>William Henry Harrison</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       president_elected president_elected_party  can_be_re_elected\n",
       "0  1824       John Quincy Adams                      DR                  1\n",
       "1  1828          Andrew Jackson                       D                  1\n",
       "2  1832          Andrew Jackson                       D                  0\n",
       "3  1836        Martin Van Buren                       D                  1\n",
       "4  1840  William Henry Harrison                       W                  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of the US presidents\n",
    "president_elected_history = pd.read_csv('data/president_elected_history.csv', sep=';')\n",
    "display(president_elected_history.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 89968: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-06d09f806234>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melections_pages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhouse_elections_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_house_elections_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m national_level_factors = data_df[[\n",
      "\u001b[1;32m<ipython-input-7-06d09f806234>\u001b[0m in \u001b[0;36mextract_house_elections_history\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mlist_of_house_elections_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'no file'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 89968: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the national level factors\n",
    "Source: https://en.wikipedia.org/wiki/United_States_presidential_election\n",
    "\"\"\"\n",
    "\n",
    "# From a tag, extract the number of seats\n",
    "def extract_seats(tag):\n",
    "    if tag.findAll('b'):\n",
    "        d_seats = tag.b.extract().string\n",
    "    elif tag.sup and tag.sup.decompose():\n",
    "        d_seats = tag.sup.decompose()\n",
    "    elif tag.string is None:\n",
    "        d_seats = tag.text\n",
    "    else:\n",
    "        d_seats = tag.string\n",
    "    return int(d_seats)\n",
    "\n",
    "def extract_seats_change(tag):\n",
    "    if tag.sup:\n",
    "        d_seats_change = tag.text.split('[', 1)[0]\n",
    "    else:\n",
    "        d_seats_change = tag.text\n",
    "    return int(d_seats_change.replace('–', '-'))\n",
    "\n",
    "# Get the house election years\n",
    "def extract_house_elections_history():\n",
    "    house_elections_history = []\n",
    "\n",
    "    # If the file doesn't exist, get the data from the webpage and store the content to a new file\n",
    "    filename = 'data/list_of_house_elections_page.html'\n",
    "    if Path(filename).is_file():\n",
    "        with open(filename) as my_file:\n",
    "            list_of_house_elections_page = my_file.read()\n",
    "    else:\n",
    "        print('no file')\n",
    "        list_of_house_elections_page = requests.get('https://en.wikipedia.org/wiki/List_of_United_States_House_of_Representatives_elections,_1856%E2%80%93present')\n",
    "        with open(filename,'w') as outfile:\n",
    "            outfile.write(list_of_house_elections_page.text)\n",
    "\n",
    "    soup = BeautifulSoup(list_of_house_elections_page, \"html.parser\")\n",
    "\n",
    "    # Find the election years\n",
    "    data = []\n",
    "    elections_pages = []\n",
    "    for t in soup.find_all('a', title=lambda x: x and 'United States House of Representatives elections,' in x):\n",
    "        if len(t.string) == 4:\n",
    "            elections_pages.append({\n",
    "                'year': int(t.string),\n",
    "                'url':'https://en.wikipedia.org'+t.attrs['href']\n",
    "            })\n",
    "            year = int(t.string)+2\n",
    "\n",
    "            cols = t.parent.parent.find_all('td')\n",
    "\n",
    "            # Get the number of Democrat seats\n",
    "            d_seats = extract_seats(cols[1])\n",
    "\n",
    "            # Get the change in the number of Democrat seats\n",
    "            d_seats_change = extract_seats_change(cols[2])\n",
    "\n",
    "            # Get the number of Republican seats\n",
    "            r_seats = extract_seats(cols[3])\n",
    "            \n",
    "            # Get the change in the number of Republican seats\n",
    "            r_seats_change_by_year = extract_seats_change(cols[4])\n",
    "            \n",
    "            #print(1 if year in presidential_years else 0)\n",
    "\n",
    "            idx = (np.abs(president_elected_history['year'].values-year+1)).argmin()\n",
    "            president_can_be_re_elected = president_elected_history['can_be_re_elected'].loc[[idx]].values[0]\n",
    "            president_party = president_elected_history['president_elected_party'].loc[[idx]].values[0]\n",
    "\n",
    "            # Look for president overall job approval average\n",
    "            president_name = president_elected_history['president_elected'].loc[[idx]].values[0]\n",
    "            president_overall_avg_job_approval = presidential_approval_df.loc[presidential_approval_df['PresidentName'] == president_name]['OverallAverage']\n",
    "            president_overall_avg_job_approval = float(president_overall_avg_job_approval.values[0])/100 if president_overall_avg_job_approval.values.size else None\n",
    "            \n",
    "            # Get the national unemployement rate for November\n",
    "            oct_unemployement_rate = national_unemployement_rate.loc[national_unemployement_rate['Year'] == year]['Oct']\n",
    "            \n",
    "            oct_unemployement_rate = oct_unemployement_rate.values[0] if oct_unemployement_rate.values.size else None\n",
    "            \n",
    "            data.append({\n",
    "                'year': year,\n",
    "                'is_presidential_year': 1 if year in president_elected_history['year'].unique() else 0,\n",
    "                'president_party': president_party,\n",
    "                'president_can_be_re_elected': president_can_be_re_elected,\n",
    "                'president_overall_avg_job_approval': president_overall_avg_job_approval,\n",
    "                'oct_unemployement_rate': oct_unemployement_rate,\n",
    "                'last_democrat_seats': d_seats,\n",
    "                'last_republican seats': r_seats,\n",
    "                'last_house_majority': 'R' if d_seats < r_seats else 'D'\n",
    "            })\n",
    "\n",
    "    return data, elections_pages\n",
    "\n",
    "data, house_elections_pages = extract_house_elections_history()\n",
    "data_df = pd.DataFrame(data)\n",
    "national_level_factors = data_df[[\n",
    "    'year', \n",
    "    'is_presidential_year', \n",
    "    'president_party', \n",
    "    'president_can_be_re_elected', \n",
    "    'president_overall_avg_job_approval', \n",
    "    'oct_unemployement_rate',\n",
    "    'last_democrat_seats', \n",
    "    'last_republican seats', \n",
    "    'last_house_majority']]\n",
    "display(national_level_factors.sort_values('year', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the state level factors\n",
    "\"\"\"\n",
    "\n",
    "# Historical presidential election results by state\n",
    "# Source: https://en.wikipedia.org/wiki/List_of_United_States_presidential_election_results_by_state\n",
    "election_results_df = pd.read_csv('data/presidential_election_results_by_state.csv')\n",
    "election_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikipedia.org\n",
    "### Get the House and Senate election result pages for all the available years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 1458927: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f9088be334d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcandidate_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m \u001b[0mdistricts_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_district_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;31m# districts_df = pd.DataFrame(districts_list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;31m# display(districts_df.loc[districts_df['state'] == 'Wyoming'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-f9088be334d8>\u001b[0m in \u001b[0;36mget_district_list\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Check if the page has been stored on disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_or_save_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Find the districts page links\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ff8568790e96>\u001b[0m in \u001b[0;36mcheck_or_save_page\u001b[1;34m(filename, url)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 1458927: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get the district level factor\n",
    "\"\"\"\n",
    "def get_district_list():\n",
    "    district_list = []\n",
    "    url = 'https://en.wikipedia.org/wiki/United_States_House_of_Representatives_elections,_2016'\n",
    "    filename = 'data/wikipedia/all_state_districts_list_page.html'\n",
    "    \n",
    "    # Check if the page has been stored on disk\n",
    "    soup = check_or_save_page(filename, url)\n",
    "    \n",
    "    # Find the districts page links\n",
    "    districts = soup.find_all('a', href=re.compile(r'(.*\\/wiki\\/.* )|(.*_congressional_district)'))\n",
    "    \n",
    "    for district in districts:\n",
    "        if any(substring in district.string for substring in states) \\\n",
    "        and district.string not in district_list \\\n",
    "        and \"'s\" not in district.string \\\n",
    "        and \"12th\" not in district.string \\\n",
    "        and '1st' not in district.string:\n",
    "            district_state = ''\n",
    "            # Get the corresponding state\n",
    "            for state in states:\n",
    "                if state in district.string:\n",
    "                    district_state = state\n",
    "            \n",
    "            # Format the district name\n",
    "            if 'at-large' in district.string:\n",
    "                dist_name = 'At-Large'\n",
    "            else:\n",
    "                # Find the district number\n",
    "                dist_number = [int(s) for s in district.string.split() if s.isdigit()]\n",
    "                if len(dist_number) > 0:\n",
    "                    dist_number = dist_number[0]\n",
    "                    dist_name = 'District {}'.format(dist_number)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "            #print(district_state, dist_name)\n",
    "            \n",
    "            district_list.append({\n",
    "                'name': dist_name,\n",
    "                'page_url': 'https://en.wikipedia.org{}'.format(district['href']),\n",
    "                'state': district_state\n",
    "            })\n",
    "            \n",
    "    # Remove duplicate in the list\n",
    "    district_list = [dict(t) for t in {tuple(d.items()) for d in district_list}]\n",
    "    \n",
    "    return district_list\n",
    "\n",
    "def get_wiki_district_pages(districts):\n",
    "    # Get the district pages if they have not been stored on disk yet\n",
    "    for district in districts:\n",
    "        filename = 'data/district_pages/{}.html'.format(district['name'])\n",
    "\n",
    "        # Check if the page has been stored on disk\n",
    "        check_or_save_page(filename, district['page_url'])\n",
    "        \n",
    "def parse_district_house_results(filename, district, state):\n",
    "    undesirable_chars = ['\\*', '%', '\\(incumbent\\)', '\\(inc.\\)', '\\(write-in\\)']\n",
    "    district_house_results = []\n",
    "    with open(filename) as my_file:\n",
    "        soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "        \n",
    "        # Find the election results tables\n",
    "        caption = soup.find_all('caption')\n",
    "        elems = []\n",
    "        for capt in caption:\n",
    "            x = capt.get_text()\n",
    "            if ('United States House of Representatives elections,' in x or\n",
    "                'congressional district election' in x or\n",
    "                'US House election, ' in x or\n",
    "                'Congressional District House Election'\n",
    "            ):\n",
    "                elems.append(capt)\n",
    "\n",
    "        for capt in elems:\n",
    "            # Find the date\n",
    "            match = re.match(r'.*([1-2][0-9]{3})', capt.text)\n",
    "            if match is None:\n",
    "                continue\n",
    "\n",
    "            # Then it found a match!\n",
    "            year = int(match.group(1))\n",
    "            #print(year)\n",
    "\n",
    "            # Get the result table itself\n",
    "            table = capt.find_parent('table')\n",
    "            table_body = table.find('tbody')\n",
    "            rows = table_body.find_all('tr')\n",
    "\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                cols = [ele for ele in cols if ele] # Get rid of empty values\n",
    "\n",
    "                if len(cols) and cols[0] in ['Republican', 'Democratic']:\n",
    "                    print(cols)\n",
    "                    \n",
    "                    percent = np.NaN\n",
    "                    if len(cols) > 3 and cols[3] != 'N/A':\n",
    "                        percent = float(re.sub(\"|\".join(undesirable_chars), \"\", cols[3]))/100\n",
    "                    \n",
    "                    votes = np.NaN\n",
    "                    if len(cols) > 2 and cols[2] == 'N/A':\n",
    "                        votes = np.NaN\n",
    "                    elif len(cols) > 2 and '%' not in cols[2] and cols[2] != '100.00':\n",
    "                        votes = int(cols[2].replace(',', '').replace('.', ''))\n",
    "                    elif len(cols) > 2 and ('%' in cols[2] or cols[2] == '100.00'):\n",
    "                        percent = float(re.sub(\"|\".join(undesirable_chars), \"\", cols[2]))/100\n",
    "                    \n",
    "                    district_house_results.append({\n",
    "                        'year': year,\n",
    "                        'candidate_party': 'R' if cols[0] == \"Republican\" else 'D',\n",
    "                        'candidate_name': re.sub(\"|\".join(undesirable_chars), \"\", cols[1]),\n",
    "                        'votes': votes,\n",
    "                        'percent': percent\n",
    "                    })\n",
    "                    \n",
    "    return pd.DataFrame(district_house_results)\n",
    "    \n",
    "def get_district_level_factors(district):\n",
    "    state = districts_df.loc[districts_df['name'] == district]['state'].values[0]\n",
    "    dist_level_factors = []\n",
    "    # Get the page of the district\n",
    "    html_filename = 'data/district_pages/{}.html'.format(district)\n",
    "    json_filename = 'data/district_pages/{}.json'.format(district)\n",
    "    \n",
    "    # If there is no already formated data, get them from the corresponding Wikipedia page\n",
    "    if Path(json_filename).is_file() is False:\n",
    "        district_house_results = parse_district_house_results(html_filename, district, state)\n",
    "        display(district_house_results)\n",
    "    else:\n",
    "        print('get from json')\n",
    "        district_house_results = pd.read_json(json_filename)\n",
    "        display(district_house_results)\n",
    "        \n",
    "    # Now, for each year\n",
    "    for year in district_house_results['year'].unique():\n",
    "        # If there is more than 1 candidate this year\n",
    "        # Get the current year\n",
    "        if len(district_house_results.loc[district_house_results['year'] == year]) > 1:\n",
    "            curr_year_idx = district_house_results.loc[district_house_results['year'] == year]['votes'].idxmax()\n",
    "            curr_year = district_house_results.loc[[curr_year_idx]]\n",
    "        else:\n",
    "            curr_year = district_house_results        \n",
    "        \n",
    "        # Get previous year\n",
    "        prev_year = district_house_results.loc[district_house_results['year'] == year-2]\n",
    "\n",
    "        if prev_year.empty is False:\n",
    "            # If there is more than 1 candidate the previous year\n",
    "            if len(prev_year) > 1:\n",
    "                prev_year_winner_idx = prev_year['votes'].idxmax()\n",
    "                prev_year_winner = prev_year.loc[[prev_year_winner_idx]]\n",
    "            else:\n",
    "                prev_year_winner = prev_year\n",
    "\n",
    "            # Get the incumbent name\n",
    "            incumbent = prev_year_winner['candidate_name'].values[0]\n",
    "\n",
    "            # Get the elections previously won by the incumbent\n",
    "            incumbent_history = district_house_results.loc[\n",
    "                (district_house_results['candidate_name'] == incumbent) &\n",
    "                (district_house_results['year'] < year)\n",
    "            ]\n",
    "\n",
    "            incubent_first_elected_idx = incumbent_history['year'].idxmin()\n",
    "            incubent_first_elected = incumbent_history.loc[[incubent_first_elected_idx]]['year'].values[0]\n",
    "            incubent_is_candidate = curr_year.loc[curr_year['candidate_name'] == incumbent].empty\n",
    "\n",
    "            dist_data = {\n",
    "                'year': year,\n",
    "                'state': state,\n",
    "                'district': district,\n",
    "                'incumbent': incumbent,\n",
    "                'incumbent_party': 'R' if prev_year_winner['candidate_party'].values[0] == \"Republican\" else 'D',\n",
    "                'incumbent_count_victories': len(incumbent_history),\n",
    "                'incumbent_first_elected': incubent_first_elected,\n",
    "                'incumbent_running_re_election': 0 if incubent_is_candidate else 1,\n",
    "                'candidate_elected_party': curr_year['candidate_party'].values[0]\n",
    "            }\n",
    "\n",
    "            dist_level_factors.append(dist_data)\n",
    "        else:\n",
    "            print('yop')\n",
    "            dist_data = {\n",
    "                'year': year,\n",
    "                'state': state,\n",
    "                'district': district,\n",
    "                'incumbent': np.NaN,\n",
    "                'incumbent_party': np.NaN,\n",
    "                'incumbent_count_victories': np.NaN,\n",
    "                'incumbent_first_elected': np.NaN,\n",
    "                'incumbent_running_re_election': np.NaN,\n",
    "                'candidate_elected_party': curr_year['candidate_party'].values[0]\n",
    "            }\n",
    "            dist_level_factors.append(dist_data)\n",
    "\n",
    "    return dist_level_factors\n",
    "\n",
    "#for district in ['Alabama 1', 'Alabama 2']:\n",
    "#for district in ['Arkansas 1']:\n",
    "#    district_level_factors = get_district_level_factors(district)\n",
    "#    display(pd.DataFrame(district_level_factors).sort_values('year', ascending=True))\n",
    "#    #display(district_level_factors)\n",
    "\n",
    "def get_wiki_districts_house_results(districts_list):\n",
    "    candidate_results = []\n",
    "    wiki_undesirable_chars = [\n",
    "        '\\*', '%', '\\(Incumbent\\)', '\\(incumbent\\)', '\\(inc.\\)', '\\(write-in\\)', \n",
    "        '\\(as a write-in\\)'\n",
    "    ]\n",
    "    for district in districts_list:\n",
    "        # To remove\n",
    "        #if district['state'] != 'Texas' or district['name'] != 'District 17':\n",
    "        #if district['state'] != 'Wyoming':\n",
    "        #    continue\n",
    "        \n",
    "        print('Will get results for house/{}/{}.html'.format(district['state'], district['name']))\n",
    "        print('Source: {}'.format(district['page_url']))\n",
    "        \n",
    "        # In some cases, the wikipedia page is too messy to crawl\n",
    "        # So I manually gather the informations into a json file\n",
    "        # If this file exist, it will be prefered\n",
    "        json_filename = 'data/wikipedia/house/{}/{}.json'.format(district['state'], district['name'])\n",
    "        if Path(json_filename).is_file() is True:\n",
    "            print('Data are store in a formated JSON')\n",
    "            continue\n",
    "        \n",
    "        # Create the directories if necessary\n",
    "        if not os.path.exists('data/wikipedia/house'):\n",
    "            os.makedirs('data/wikipedia/house')\n",
    "        if not os.path.exists('data/wikipedia/house/{}'.format(district['state'])):\n",
    "            os.makedirs('data/wikipedia/house/{}'.format(district['state']))\n",
    "            \n",
    "        filename = 'data/wikipedia/house/{}/{}.html'.format(district['state'], district['name'])\n",
    "        \n",
    "        # Check if the page has been stored on disk\n",
    "        soup = check_or_save_page(filename, district['page_url'])\n",
    "        \n",
    "        # Find the results tables\n",
    "        caption = soup.find_all('caption')\n",
    "        tables = []\n",
    "        for capt in caption:\n",
    "            x = capt.get_text()\n",
    "            if ('United States House of Representatives elections,' in x or\n",
    "                'congressional district election' in x or\n",
    "                'US House election, ' in x or\n",
    "                'Congressional District House Election'\n",
    "            ):\n",
    "                # print(capt)\n",
    "                table = capt.find_parent('table')\n",
    "                tables.append(table)\n",
    "        \n",
    "        # For each result table, extract the results\n",
    "        for table in tables:\n",
    "            # Get the year\n",
    "            table_title = table.find('caption')\n",
    "            \n",
    "            # If this is a table about a special election, skip it\n",
    "            if 'Special' in table_title.text:\n",
    "                continue\n",
    "            \n",
    "            year_match = re.match(r'.*([1-2][0-9]{3})', table_title.text)\n",
    "            \n",
    "            # If there is no year match, then this table isn't of interest\n",
    "            if year_match is None:\n",
    "                continue\n",
    "            \n",
    "            year = int(year_match.group(1))\n",
    "            # print(year)\n",
    "            \n",
    "            # Get the result table itself\n",
    "            rows = table.find('tbody').find_all('tr')\n",
    "            candidate_rows = []\n",
    "            for row in rows:\n",
    "                cols = row.find_all('td')\n",
    "                cols = [ele.text.strip() for ele in cols]\n",
    "                # If all the values of the cols are empty strings, continue\n",
    "                if all(v is '' for v in cols):\n",
    "                    continue\n",
    "                    \n",
    "                # print(cols)\n",
    "                \n",
    "                # If this row contains a candidate results\n",
    "                if len(cols) > 2 and cols[1] in ['Republican', 'Democratic']:\n",
    "                    # print(cols)\n",
    "                    \n",
    "                    party = 'R' if cols[1] == 'Republican' else 'D'\n",
    "                    name = cols[2]\n",
    "                    votes = int(cols[3].replace(',', '').replace('[8]', '').replace('c', '').replace('.', '').replace(' ', '')) if cols[3] != '' else np.NaN\n",
    "                    percent = float(cols[4].replace('%', '')) if cols[4] != '' else np.NaN\n",
    "                    \n",
    "                    candidate_rows.append({\n",
    "                        'year': year,\n",
    "                        'state': district['state'],\n",
    "                        'district': district['name'],\n",
    "                        'is_incumbent': np.NaN,\n",
    "                        'name': name,\n",
    "                        'party': party,\n",
    "                        'percent': percent,\n",
    "                        'votes': votes,\n",
    "                        'won': 0\n",
    "                    })\n",
    "                    \n",
    "            # If we found no candidate data, continue\n",
    "            if len(candidate_rows) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Enrich the candidates data\n",
    "            max_percent = max([x['percent'] for x in candidate_rows])\n",
    "            for candidate in candidate_rows:\n",
    "                # Check if the candidate won the elections\n",
    "                if candidate['percent'] == max_percent:\n",
    "                    candidate['won'] = 1\n",
    "                    \n",
    "                # Check if we can determine if the candidate is an incumbent\n",
    "                if '(inc.)' in candidate['name'] or '(incumbent)' in candidate['name'] or '(Incumbent)' in candidate['name']:\n",
    "                    candidate['is_incumbent'] = 1\n",
    "\n",
    "                # Clean the candidate name\n",
    "                candidate['name'] = re.sub(\"|\".join(wiki_undesirable_chars), \"\", candidate['name'])\n",
    "                    \n",
    "                candidate_results.append(candidate)\n",
    "                \n",
    "            # If we found that one of the candidates is an incumbent, the others are sets to 0\n",
    "            max_incumbent = max([x['is_incumbent'] for x in candidate_rows])\n",
    "            #print(type(max_incumbent))\n",
    "            if max_incumbent == 1:\n",
    "                for candidate in candidate_rows:\n",
    "                    candidate['is_incumbent'] = 0 if candidate['is_incumbent'] != 1 else 1\n",
    "\n",
    "    return candidate_results\n",
    "\n",
    "districts_list = get_district_list()\n",
    "# districts_df = pd.DataFrame(districts_list)\n",
    "# display(districts_df.loc[districts_df['state'] == 'Wyoming'])\n",
    "\n",
    "wiki_house_history = get_wiki_districts_house_results(districts_list)\n",
    "# Store in disk\n",
    "wiki_house_history_df = pd.DataFrame(wiki_house_history)\n",
    "wiki_house_history_df.to_csv('data/wikipedia/house_results.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now have on disk ALL the available historical district results from Wikipedia**\n",
    "\n",
    "Lets take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>is_incumbent</th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>percent</th>\n",
       "      <th>state</th>\n",
       "      <th>votes</th>\n",
       "      <th>won</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>85.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>160136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>78.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>106059.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andy Wilson</td>\n",
       "      <td>D</td>\n",
       "      <td>19.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>25984.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>72.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>168501.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dwight Fullingim</td>\n",
       "      <td>D</td>\n",
       "      <td>25.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>58030.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>68.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>92811.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robert Ricketts</td>\n",
       "      <td>D</td>\n",
       "      <td>30.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>40853.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>58.40</td>\n",
       "      <td>Texas</td>\n",
       "      <td>136459.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Charles Stenholm</td>\n",
       "      <td>D</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Texas</td>\n",
       "      <td>93531.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Clair Burgener</td>\n",
       "      <td>R</td>\n",
       "      <td>67.40</td>\n",
       "      <td>California</td>\n",
       "      <td>155965.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bob Lowe</td>\n",
       "      <td>D</td>\n",
       "      <td>29.20</td>\n",
       "      <td>California</td>\n",
       "      <td>67477.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lionel Van Deerlin</td>\n",
       "      <td>D</td>\n",
       "      <td>69.90</td>\n",
       "      <td>California</td>\n",
       "      <td>69746.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wes Marden</td>\n",
       "      <td>R</td>\n",
       "      <td>30.10</td>\n",
       "      <td>California</td>\n",
       "      <td>30058.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lionel Van Deerlin</td>\n",
       "      <td>D</td>\n",
       "      <td>76.00</td>\n",
       "      <td>California</td>\n",
       "      <td>103062.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wes Marden</td>\n",
       "      <td>R</td>\n",
       "      <td>24.00</td>\n",
       "      <td>California</td>\n",
       "      <td>32565.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lionel Van Deerlin</td>\n",
       "      <td>D</td>\n",
       "      <td>73.70</td>\n",
       "      <td>California</td>\n",
       "      <td>85126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lawrence C. Mattera</td>\n",
       "      <td>R</td>\n",
       "      <td>26.30</td>\n",
       "      <td>California</td>\n",
       "      <td>30319.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>District 42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Duncan Hunter</td>\n",
       "      <td>R</td>\n",
       "      <td>53.30</td>\n",
       "      <td>California</td>\n",
       "      <td>79713.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lionel Van Deerlin</td>\n",
       "      <td>D</td>\n",
       "      <td>46.70</td>\n",
       "      <td>California</td>\n",
       "      <td>69936.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dan Lungren</td>\n",
       "      <td>R</td>\n",
       "      <td>69.00</td>\n",
       "      <td>California</td>\n",
       "      <td>142845.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>James P. Spellman</td>\n",
       "      <td>D</td>\n",
       "      <td>28.30</td>\n",
       "      <td>California</td>\n",
       "      <td>58690.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dan Lungren</td>\n",
       "      <td>R</td>\n",
       "      <td>73.00</td>\n",
       "      <td>California</td>\n",
       "      <td>177783.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mary Lou Brophy</td>\n",
       "      <td>D</td>\n",
       "      <td>24.60</td>\n",
       "      <td>California</td>\n",
       "      <td>60025.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dan Lungren</td>\n",
       "      <td>R</td>\n",
       "      <td>72.80</td>\n",
       "      <td>California</td>\n",
       "      <td>140364.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Michael P. Blackburn</td>\n",
       "      <td>D</td>\n",
       "      <td>24.70</td>\n",
       "      <td>California</td>\n",
       "      <td>47586.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>District 42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dana Rohrabacher</td>\n",
       "      <td>R</td>\n",
       "      <td>64.20</td>\n",
       "      <td>California</td>\n",
       "      <td>153280.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>District 42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Guy C. Kimbrough</td>\n",
       "      <td>D</td>\n",
       "      <td>33.00</td>\n",
       "      <td>California</td>\n",
       "      <td>78778.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dana Rohrabacher</td>\n",
       "      <td>R</td>\n",
       "      <td>59.30</td>\n",
       "      <td>California</td>\n",
       "      <td>109353.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>District 42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Guy C. Kimbrough</td>\n",
       "      <td>D</td>\n",
       "      <td>36.50</td>\n",
       "      <td>California</td>\n",
       "      <td>67189.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>District 42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>George Brown, Jr.</td>\n",
       "      <td>D</td>\n",
       "      <td>50.70</td>\n",
       "      <td>California</td>\n",
       "      <td>79780.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8240</th>\n",
       "      <td>District 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>George Holding</td>\n",
       "      <td>R</td>\n",
       "      <td>56.71</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>221485.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8241</th>\n",
       "      <td>District 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John P. McNeil</td>\n",
       "      <td>D</td>\n",
       "      <td>43.29</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>169082.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>55.00</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>220628.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8243</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Art Robinson</td>\n",
       "      <td>R</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>157743.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8244</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>59.00</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>181624.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8245</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Art Robinson</td>\n",
       "      <td>R</td>\n",
       "      <td>38.00</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>116534.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8246</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>59.10</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>208196.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8247</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Art Robinson</td>\n",
       "      <td>R</td>\n",
       "      <td>39.20</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>138351.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8248</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>54.49</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>162416.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8249</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Art Robinson</td>\n",
       "      <td>R</td>\n",
       "      <td>43.58</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>129877.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8250</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>82.34</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>275143.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8251</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>62.23</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>180607.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8252</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jim Feldkamp</td>\n",
       "      <td>R</td>\n",
       "      <td>37.59</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>109105.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8253</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>60.98</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>228611.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8254</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jim Feldkamp</td>\n",
       "      <td>R</td>\n",
       "      <td>37.58</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>140882.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8255</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>63.86</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>168150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liz VanLeeuwen</td>\n",
       "      <td>R</td>\n",
       "      <td>34.36</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>90523.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8257</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>68.03</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>197998.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8258</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John Lindsey</td>\n",
       "      <td>R</td>\n",
       "      <td>30.56</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>88950.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8259</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>70.12</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>157524.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8260</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Steve J. Webb</td>\n",
       "      <td>R</td>\n",
       "      <td>28.55</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>64143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peter DeFazio</td>\n",
       "      <td>D</td>\n",
       "      <td>65.69</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>177270.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>District 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John D. Newkirk</td>\n",
       "      <td>R</td>\n",
       "      <td>28.40</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>76649.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8263</th>\n",
       "      <td>District 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jim McGovern</td>\n",
       "      <td>D</td>\n",
       "      <td>73.34</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>155697.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8264</th>\n",
       "      <td>District 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jim McGovern</td>\n",
       "      <td>D</td>\n",
       "      <td>67.15</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>192036.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8265</th>\n",
       "      <td>District 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ronald Crews</td>\n",
       "      <td>R</td>\n",
       "      <td>28.04</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>80197.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8266</th>\n",
       "      <td>District 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jim McGovern</td>\n",
       "      <td>D</td>\n",
       "      <td>77.63</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>166973.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>District 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jim McGovern</td>\n",
       "      <td>D</td>\n",
       "      <td>75.04</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>227619.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8268</th>\n",
       "      <td>District 3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jim McGovern</td>\n",
       "      <td>D</td>\n",
       "      <td>56.50</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>122357.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8269</th>\n",
       "      <td>District 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Marty Lamb</td>\n",
       "      <td>R</td>\n",
       "      <td>39.20</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>84972.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8270 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         district  is_incumbent                  name party  percent  \\\n",
       "0     District 19           NaN      Randy Neugebauer     R    85.00   \n",
       "1     District 19           NaN      Randy Neugebauer     R    78.00   \n",
       "2     District 19           NaN           Andy Wilson     D    19.00   \n",
       "3     District 19           NaN      Randy Neugebauer     R    72.00   \n",
       "4     District 19           NaN      Dwight Fullingim     D    25.00   \n",
       "5     District 19           NaN      Randy Neugebauer     R    68.00   \n",
       "6     District 19           NaN       Robert Ricketts     D    30.00   \n",
       "7     District 19           NaN      Randy Neugebauer     R    58.40   \n",
       "8     District 19           NaN      Charles Stenholm     D    40.00   \n",
       "9     District 42           1.0       Clair Burgener      R    67.40   \n",
       "10    District 42           0.0              Bob Lowe     D    29.20   \n",
       "11    District 42           1.0   Lionel Van Deerlin      D    69.90   \n",
       "12    District 42           0.0            Wes Marden     R    30.10   \n",
       "13    District 42           1.0   Lionel Van Deerlin      D    76.00   \n",
       "14    District 42           0.0            Wes Marden     R    24.00   \n",
       "15    District 42           1.0   Lionel Van Deerlin      D    73.70   \n",
       "16    District 42           0.0   Lawrence C. Mattera     R    26.30   \n",
       "17    District 42           NaN         Duncan Hunter     R    53.30   \n",
       "18    District 42           1.0   Lionel Van Deerlin      D    46.70   \n",
       "19    District 42           1.0          Dan Lungren      R    69.00   \n",
       "20    District 42           0.0     James P. Spellman     D    28.30   \n",
       "21    District 42           1.0          Dan Lungren      R    73.00   \n",
       "22    District 42           0.0       Mary Lou Brophy     D    24.60   \n",
       "23    District 42           1.0          Dan Lungren      R    72.80   \n",
       "24    District 42           0.0  Michael P. Blackburn     D    24.70   \n",
       "25    District 42           NaN      Dana Rohrabacher     R    64.20   \n",
       "26    District 42           NaN      Guy C. Kimbrough     D    33.00   \n",
       "27    District 42           1.0     Dana Rohrabacher      R    59.30   \n",
       "28    District 42           0.0      Guy C. Kimbrough     D    36.50   \n",
       "29    District 42           1.0    George Brown, Jr.      D    50.70   \n",
       "...           ...           ...                   ...   ...      ...   \n",
       "8240   District 2           NaN        George Holding     R    56.71   \n",
       "8241   District 2           NaN        John P. McNeil     D    43.29   \n",
       "8242   District 4           NaN         Peter DeFazio     D    55.00   \n",
       "8243   District 4           NaN          Art Robinson     R    40.00   \n",
       "8244   District 4           NaN         Peter DeFazio     D    59.00   \n",
       "8245   District 4           NaN          Art Robinson     R    38.00   \n",
       "8246   District 4           NaN         Peter DeFazio     D    59.10   \n",
       "8247   District 4           NaN          Art Robinson     R    39.20   \n",
       "8248   District 4           NaN         Peter DeFazio     D    54.49   \n",
       "8249   District 4           NaN          Art Robinson     R    43.58   \n",
       "8250   District 4           NaN         Peter DeFazio     D    82.34   \n",
       "8251   District 4           NaN         Peter DeFazio     D    62.23   \n",
       "8252   District 4           NaN          Jim Feldkamp     R    37.59   \n",
       "8253   District 4           NaN         Peter DeFazio     D    60.98   \n",
       "8254   District 4           NaN          Jim Feldkamp     R    37.58   \n",
       "8255   District 4           NaN         Peter DeFazio     D    63.86   \n",
       "8256   District 4           NaN        Liz VanLeeuwen     R    34.36   \n",
       "8257   District 4           NaN         Peter DeFazio     D    68.03   \n",
       "8258   District 4           NaN          John Lindsey     R    30.56   \n",
       "8259   District 4           NaN         Peter DeFazio     D    70.12   \n",
       "8260   District 4           NaN         Steve J. Webb     R    28.55   \n",
       "8261   District 4           NaN         Peter DeFazio     D    65.69   \n",
       "8262   District 4           NaN       John D. Newkirk     R    28.40   \n",
       "8263   District 3           1.0         Jim McGovern      D    73.34   \n",
       "8264   District 3           1.0         Jim McGovern      D    67.15   \n",
       "8265   District 3           0.0          Ronald Crews     R    28.04   \n",
       "8266   District 3           1.0         Jim McGovern      D    77.63   \n",
       "8267   District 3           1.0         Jim McGovern      D    75.04   \n",
       "8268   District 3           1.0         Jim McGovern      D    56.50   \n",
       "8269   District 3           0.0            Marty Lamb     R    39.20   \n",
       "\n",
       "               state     votes  won  year  \n",
       "0              Texas  160136.0    1  2012  \n",
       "1              Texas  106059.0    1  2010  \n",
       "2              Texas   25984.0    0  2010  \n",
       "3              Texas  168501.0    1  2008  \n",
       "4              Texas   58030.0    0  2008  \n",
       "5              Texas   92811.0    1  2006  \n",
       "6              Texas   40853.0    0  2006  \n",
       "7              Texas  136459.0    1  2004  \n",
       "8              Texas   93531.0    0  2004  \n",
       "9         California  155965.0    1  1972  \n",
       "10        California   67477.0    0  1972  \n",
       "11        California   69746.0    1  1974  \n",
       "12        California   30058.0    0  1974  \n",
       "13        California  103062.0    1  1976  \n",
       "14        California   32565.0    0  1976  \n",
       "15        California   85126.0    1  1978  \n",
       "16        California   30319.0    0  1978  \n",
       "17        California   79713.0    1  1980  \n",
       "18        California   69936.0    0  1980  \n",
       "19        California  142845.0    1  1982  \n",
       "20        California   58690.0    0  1982  \n",
       "21        California  177783.0    1  1984  \n",
       "22        California   60025.0    0  1984  \n",
       "23        California  140364.0    1  1986  \n",
       "24        California   47586.0    0  1986  \n",
       "25        California  153280.0    1  1988  \n",
       "26        California   78778.0    0  1988  \n",
       "27        California  109353.0    1  1990  \n",
       "28        California   67189.0    0  1990  \n",
       "29        California   79780.0    1  1992  \n",
       "...              ...       ...  ...   ...  \n",
       "8240  North Carolina  221485.0    1  2016  \n",
       "8241  North Carolina  169082.0    0  2016  \n",
       "8242          Oregon  220628.0    1  2016  \n",
       "8243          Oregon  157743.0    0  2016  \n",
       "8244          Oregon  181624.0    1  2014  \n",
       "8245          Oregon  116534.0    0  2014  \n",
       "8246          Oregon  208196.0    1  2012  \n",
       "8247          Oregon  138351.0    0  2012  \n",
       "8248          Oregon  162416.0    1  2010  \n",
       "8249          Oregon  129877.0    0  2010  \n",
       "8250          Oregon  275143.0    1  2008  \n",
       "8251          Oregon  180607.0    1  2006  \n",
       "8252          Oregon  109105.0    0  2006  \n",
       "8253          Oregon  228611.0    1  2004  \n",
       "8254          Oregon  140882.0    0  2004  \n",
       "8255          Oregon  168150.0    1  2002  \n",
       "8256          Oregon   90523.0    0  2002  \n",
       "8257          Oregon  197998.0    1  2000  \n",
       "8258          Oregon   88950.0    0  2000  \n",
       "8259          Oregon  157524.0    1  1998  \n",
       "8260          Oregon   64143.0    0  1998  \n",
       "8261          Oregon  177270.0    1  1996  \n",
       "8262          Oregon   76649.0    0  1996  \n",
       "8263   Massachusetts  155697.0    1  2002  \n",
       "8264   Massachusetts  192036.0    1  2004  \n",
       "8265   Massachusetts   80197.0    0  2004  \n",
       "8266   Massachusetts  166973.0    1  2006  \n",
       "8267   Massachusetts  227619.0    1  2008  \n",
       "8268   Massachusetts  122357.0    1  2010  \n",
       "8269   Massachusetts   84972.0    0  2010  \n",
       "\n",
       "[8270 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv('data/wikipedia/house_results.csv', index_col=0)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ballotpedia.org\n",
    "\n",
    "So far so good but the 2018 results are missing on Wikipedia and the available data are not always exhaustives. So I decided to get the same informations from a different source: Ballotpedia.  \n",
    "Here we have the complete 2018 results as well as historical date from 2012.  \n",
    "Note that the incumbent information is consistent.  \n",
    "\n",
    "### Get the House and Senate election result pages for all the available years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x90 in position 246930: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d1f94f2e6cb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_district_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[0mhouse_state_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msenate_state_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_house_senate_state_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[0mstate_district_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_house_senate_state_districts_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhouse_state_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-d1f94f2e6cb2>\u001b[0m in \u001b[0;36mget_house_senate_state_list\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# Check if the page has been stored on disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_or_save_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Find the list of the U.S. Senate Elections by State (2018) pages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ff8568790e96>\u001b[0m in \u001b[0;36mcheck_or_save_page\u001b[1;34m(filename, url)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x90 in position 246930: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "def get_house_senate_state_list():\n",
    "    house_state_list = []\n",
    "    senate_state_list = []\n",
    "    filename = 'data/ballotpedia/house_state_list_src.html'\n",
    "    url = 'https://ballotpedia.org/U.S._House_battlegrounds,_2018'\n",
    "    \n",
    "    # Check if the page has been stored on disk\n",
    "    soup = check_or_save_page(filename, url)\n",
    "    \n",
    "    # Find the list of the U.S. Senate Elections by State (2018) pages\n",
    "    table = soup.find('table', { 'class': 'infobox' })\n",
    "    for link in table.find_all('a', href=lambda x: x and '/United_States_Senate_election_in_' in x):\n",
    "        senate_state_list.append({\n",
    "            'state': link.text,\n",
    "            'url': 'https://ballotpedia.org{}'.format(link['href'])\n",
    "        })\n",
    "\n",
    "    # Find the list of the U.S. House Elections by State (2018) pages\n",
    "    table = soup.find('table', { 'class': 'infobox' })\n",
    "    for link in table.find_all('a', href=lambda x: x and (\n",
    "        '/United_States_House_of_Representatives_election_in_' in x or\n",
    "        '/United_States_House_of_Representatives_elections_in_' in x\n",
    "    )):\n",
    "        house_state_list.append({\n",
    "            'state': link.text,\n",
    "            'url': 'https://ballotpedia.org{}'.format(link['href'])\n",
    "        })\n",
    "\n",
    "    return house_state_list, senate_state_list\n",
    "\n",
    "def get_district_pages(dict_page_url, year, state, district):\n",
    "    \"\"\" \n",
    "        Recursively get all available previous election result pages\n",
    "        for a given district\n",
    "    \"\"\"\n",
    "    print('Will get house/{}/{}/{}.html'.format(state, district, year))\n",
    "    # Create the directories if necessary\n",
    "    if not os.path.exists('data/ballotpedia/house/'):\n",
    "        os.makedirs('data/ballotpedia/house/')\n",
    "    if not os.path.exists('data/ballotpedia/house/{}'.format(state)):\n",
    "        os.makedirs('data/ballotpedia/house/{}'.format(state))\n",
    "    if not os.path.exists('data/ballotpedia/house/{}/{}'.format(state, district)):\n",
    "        os.makedirs('data/ballotpedia/house/{}/{}'.format(state, district))\n",
    "    \n",
    "    filename = 'data/ballotpedia/house/{}/{}/{}.html'.format(state, district, year)\n",
    "    dict_soup = check_or_save_page(filename, dict_page_url)\n",
    "    \n",
    "    # Check if there is a link to a previous electoral year for this state\n",
    "    table = dict_soup.find('table', { 'class': 'infobox' })\n",
    "    div = table.find('div', style=lambda x: x and '#A3B1BF' in x and 'float:left;' in x)\n",
    "            \n",
    "    # If there is one\n",
    "    if div is not None:\n",
    "        # Extract the link election year\n",
    "        prev_year = int(re.match(r'.*([1-2][0-9]{3})', div.text).group(1))\n",
    "        \n",
    "        if prev_year < year:                \n",
    "            # Get the link to this disctict House election results parge\n",
    "            link = div.find('a')\n",
    "            #print(link['href'])\n",
    "\n",
    "            # Get this page\n",
    "            url = 'https://ballotpedia.org{}'.format(link['href'])\n",
    "            get_district_pages(url, prev_year, state, district)\n",
    "\n",
    "def get_house_senate_state_districts_list(house_state_list):\n",
    "    start_year = 2018\n",
    "    state_district_list = []\n",
    "    for house_state in house_state_list:\n",
    "        # To remove\n",
    "        #if house_state['state'] != 'Maryland':\n",
    "        #    continue\n",
    "\n",
    "        filename = 'data/ballotpedia/2018_house_{}.html'.format(house_state['state'])\n",
    "        \n",
    "        # Check if the page has been stored on disk\n",
    "        soup = check_or_save_page(filename, house_state['url'])\n",
    "        #print(soup)\n",
    "        \n",
    "        # Get the district page links\n",
    "        table = soup.find('table', { 'class': 'infobox' })\n",
    "        \n",
    "        links = table.find_all('a', href=lambda x: x and (\n",
    "            '_Congressional_District_election,_' in x\n",
    "        ))\n",
    "        \n",
    "        if len(links) == 0:\n",
    "            title = soup.find('b', text=lambda x : x and 'District Pages' in x)\n",
    "            links = title.parent.parent.find_all('a', href=lambda x: x and (\n",
    "                '_Congressional_District_election,_' in x\n",
    "            ))\n",
    "\n",
    "        for link in links:\n",
    "            print(link.text)\n",
    "            url = 'https://ballotpedia.org{}'.format(link['href'])\n",
    "            state_district_list.append({\n",
    "                'state': house_state['state'],\n",
    "                'district': link.text\n",
    "            })\n",
    "            #print(' |-', url)\n",
    "\n",
    "            # Get the page\n",
    "            get_district_pages(url, start_year, house_state['state'], link.text)\n",
    "            \n",
    "    return state_district_list\n",
    "\n",
    "house_state_list, senate_state_list = get_house_senate_state_list()\n",
    "state_district_list = get_house_senate_state_districts_list(house_state_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the House election results for every districts and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_district_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-97e4aaedd90a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[0mballo_house_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_district_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_district_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;31m# Store on disk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'state_district_list' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_district_data(state_district_list):\n",
    "    results = []\n",
    "    undesirable_chars = ['\\*', '%', 'Incumbent', '\\(D\\)', '\\(R\\)']\n",
    "    for item in state_district_list:\n",
    "        # To remove\n",
    "        #if item['state'] != 'New Hampshire' or item['district'] != 'District 2':\n",
    "        #if item['state'] != 'Wyoming':\n",
    "        #    continue\n",
    "\n",
    "        # Get the pages\n",
    "        directory = 'data/ballotpedia/house/{}/{}'.format(item['state'], item['district'])\n",
    "        files = [f for f in listdir(directory) if isfile(join(directory, f))]\n",
    "        \n",
    "        # For each year, get the district data\n",
    "        for file in files:\n",
    "            # Extract the year\n",
    "            year = int(re.match(r'.*([1-2][0-9]{3})', file).group(1))\n",
    "            candidate_rows = []\n",
    "            \n",
    "            # To remove\n",
    "            #if year != 2018:\n",
    "            #    continue\n",
    "            \n",
    "            # Get the page content\n",
    "            filename = 'data/ballotpedia/house/{}/{}/{}'.format(item['state'], item['district'], file)\n",
    "            with open(filename) as my_file:\n",
    "                soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "            \n",
    "            # The 2018 pages requires a different approach\n",
    "            if year == 2018:\n",
    "                #print(2018)\n",
    "                # Find the result table\n",
    "                table = soup.find('table',  { 'class': 'results_table' })\n",
    "                rows = table.find_all('tr')\n",
    "                \n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [ele.text.strip() for ele in cols]\n",
    "                    cols = [ele for ele in cols if ele] # Get rid of empty values\n",
    "                    \n",
    "                    # Check if is incumbant\n",
    "                    incumbent = 1 if row.find('b') and row.find('b').find('u') else 0\n",
    "                    #print(cols)\n",
    "                    if len(cols) == 4 and cols[0] == '✔':\n",
    "                        is_winner = 1\n",
    "                        name = cols[1] +' Incumbent' if incumbent == 1 else cols[1]\n",
    "                        percent = cols[2] if len(cols) > 1 else np.NaN\n",
    "                        votes = cols[3] if len(cols) > 2 else np.NaN\n",
    "                        party = 'Democratic' if '(D)' in cols[1] else 'Republican'\n",
    "                        candidate_rows.append([party, name, percent, votes, is_winner])\n",
    "                        \n",
    "                    elif len(cols) == 3 and '(D)' in cols[0] or '(R)' in cols[0]:\n",
    "                        is_winner = 0\n",
    "                        name = cols[0] +' Incumbent' if incumbent == 1 else cols[0]\n",
    "                        percent = cols[1] if len(cols) > 1 else np.NaN\n",
    "                        \n",
    "                        votes = cols[2] if len(cols) > 2 else np.NaN\n",
    "                        if len(cols) > 1:\n",
    "                            party = 'Democratic' if '(D)' in cols[0] else 'Republican'\n",
    "                        else:\n",
    "                            party = np.NaN\n",
    "                            \n",
    "                        candidate_rows.append([party, name, percent, votes, is_winner])\n",
    "                \n",
    "            else:            \n",
    "                # Find the result table\n",
    "                th = soup.find('th', colspan='5', style=lambda x: x and 'background-color:#444' in x)\n",
    "                table = th.find_parent('table')\n",
    "                #table_body = table.find('tbody')\n",
    "                rows = table.find_all('tr')\n",
    "                #print(rows)\n",
    "\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')\n",
    "                    cols = [ele.text.strip() for ele in cols]\n",
    "                    cols = [ele for ele in cols if ele] # Get rid of empty values\n",
    "\n",
    "                    # Ignore the rows not about the candidates\n",
    "                    if 'Republican' not in cols and not 'Democratic' in cols:\n",
    "                        continue\n",
    "\n",
    "                    # Check if the candidate won the elections\n",
    "                    is_winner = 1 if row.find('a', title=\"Won\") else 0\n",
    "                    cols.append(is_winner)\n",
    "                    candidate_rows.append(cols)\n",
    "                    \n",
    "            # If there was only one candidate\n",
    "            if len(candidate_rows) == 1:\n",
    "                if type(candidate_rows[0][3]) is int:\n",
    "                    candidate_rows[0].append(candidate_rows[0][3])\n",
    "                    candidate_rows[0][3] = np.NaN\n",
    "\n",
    "            for candidate in candidate_rows:\n",
    "                #print(year, item['district'], candidate)\n",
    "                \n",
    "                # Get and format the candidate party\n",
    "                candidate_party = 'R' if candidate[0] == 'Republican' else 'D'\n",
    "                \n",
    "                # Get and clean the candidate name\n",
    "                candidate_name = re.sub(\"|\".join(undesirable_chars), \"\", candidate[1]).rstrip()\n",
    "                \n",
    "                # Get and clean the candidate percent\n",
    "                if type(candidate[2]) is str:\n",
    "                    candidate_percent = float(candidate[2].replace('%', ''))\n",
    "                else:\n",
    "                    candidate_percent = candidate[2]\n",
    "                \n",
    "                # Get and clean the candidate vote\n",
    "                if type(candidate[3]) is str:\n",
    "                    candidate_vote = int(candidate[3].replace(',', ''))\n",
    "                else:\n",
    "                    candidate_vote = candidate[3]\n",
    "                \n",
    "                # Determine whether or not the candidate is incumbent\n",
    "                candidate_is_incumbent = 1 if 'Incumbent' in candidate[1] else 0\n",
    "                \n",
    "                results.append({\n",
    "                    'year': year,\n",
    "                    'state': item['state'],\n",
    "                    'district': item['district'] if item['district'] != 'General election' else 'At-Large',\n",
    "                    'name': candidate_name,\n",
    "                    'party': candidate_party,\n",
    "                    'percent': candidate_percent,\n",
    "                    'votes': candidate_vote,\n",
    "                    'is_incumbent': candidate_is_incumbent,\n",
    "                    'won': candidate[4]\n",
    "                })\n",
    "                \n",
    "                #print(results)\n",
    "                #print('')\n",
    "\n",
    "        #soup = BeautifulSoup(my_file.read(), \"html.parser\")\n",
    "        #print(soup)\n",
    "    return results\n",
    "\n",
    "ballo_house_history = extract_district_data(state_district_list)\n",
    "\n",
    "# Store on disk\n",
    "ballo_house_history_df = pd.DataFrame(ballo_house_history)\n",
    "ballo_house_history_df.to_csv('data/ballotpedia/ballo_results.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the data from wikipedia.org and  ballotpedia.org\n",
    "\n",
    "Now we have two dataset with the same columns and some overlaping data. Its time to merge them.  \n",
    "It appears that the data from ballotpedia.org are more consistent so we will favor them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>is_incumbent</th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>percent</th>\n",
       "      <th>state</th>\n",
       "      <th>votes</th>\n",
       "      <th>won</th>\n",
       "      <th>year</th>\n",
       "      <th>unemp_rate_16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>106059.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andy Wilson</td>\n",
       "      <td>D</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>25984.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>168501.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dwight Fullingim</td>\n",
       "      <td>D</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>58030.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>District 19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Randy Neugebauer</td>\n",
       "      <td>R</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Texas</td>\n",
       "      <td>92811.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      district  is_incumbent              name party  percent  state  \\\n",
       "1  District 19           NaN  Randy Neugebauer     R     78.0  Texas   \n",
       "2  District 19           NaN       Andy Wilson     D     19.0  Texas   \n",
       "3  District 19           NaN  Randy Neugebauer     R     72.0  Texas   \n",
       "4  District 19           NaN  Dwight Fullingim     D     25.0  Texas   \n",
       "5  District 19           NaN  Randy Neugebauer     R     68.0  Texas   \n",
       "\n",
       "      votes  won  year  unemp_rate_16  \n",
       "1  106059.0    1  2010            NaN  \n",
       "2   25984.0    0  2010            NaN  \n",
       "3  168501.0    1  2008            NaN  \n",
       "4   58030.0    0  2008            NaN  \n",
       "5   92811.0    1  2006            NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ballo_df = pd.read_csv('data/ballotpedia/ballo_results.csv', index_col=0)\n",
    "wikipedia_df = pd.read_csv('data/wikipedia/house_results.csv', index_col=0)\n",
    "\n",
    "merged_df =  pd.concat([wikipedia_df.loc[wikipedia_df['year'] < 2012], ballo_df])\n",
    "\n",
    "unemp_df = pd.read_csv('data/unemployment/unemp_2012_2017.csv',sep=';')\n",
    "unemp_df = unemp_df[['year','state','district','unemp_rate_16']]\n",
    "unemp_df['state'] = unemp_df['state'].str.rsplit(',').str[-1].str.strip()\n",
    "unemp_df['district'] = unemp_df.district.str.extract('(\\d+)').astype(int)\n",
    "unemp_df = unemp_df[unemp_df['district'] < 100]\n",
    "unemp_df['district'] = 'District ' + unemp_df['district'].astype(str)\n",
    "\n",
    "merged_df = merged_df.join(unemp_df.set_index(['year', 'state', 'district']), on=['year', 'state', 'district']).copy()\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
